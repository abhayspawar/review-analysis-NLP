{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "from Sentiment_analysis import *\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import proj_base\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lst = []\n",
    "# file_list = sorted(listdir('./Review_Texts/'))\n",
    "# for i in range(500):\n",
    "#     filename = file_list[i]\n",
    "# #     intColumns = ['No. Reader', 'No. Helpful', 'Cleanliness','Check in / front desk', 'Value', 'Overall', 'Service', 'Business service', 'Rooms', 'Location']\n",
    "#     characterThreshold = 60\n",
    "#     with open('./Review_Texts/'+filename, 'r') as content_file:\n",
    "#         content = content_file.read()\n",
    "        \n",
    "#         #print(repr(content))\n",
    "#     if content.count(\"\\r\") > 0:\n",
    "#         reviews = content.split(\"\\r\\n\\r\\n\")\n",
    "#     else:\n",
    "#         reviews = content.split(\"\\n\\n\")\n",
    "    \n",
    "#     count = 0\n",
    "#     for r in reviews:\n",
    "#         thisReview = {}\n",
    "#         splt = r.split(\"\\n\")\n",
    "#         for s in splt:\n",
    "#             for c in ['Content']:\n",
    "#                 if \"<\"+c+\">\" in s:\n",
    "#                     value = s.replace('<'+c+'>', '')\n",
    "#                     if c in intColumns:\n",
    "#                         value = int(value)\n",
    "#                     if value == -1: #we dont want -1 as this is going to mess up averaging, take np.nan\n",
    "#                         value = np.nan\n",
    "\n",
    "#                     if c == \"Content\":\n",
    "#                         value = unidecode(unicode(value.lower(), encoding=\"utf-8\"))\n",
    "\n",
    "#                     thisReview[c] = value\n",
    "                    \n",
    "#         if not thisReview.get(\"Content\") == None and len(thisReview[\"Content\"]) > 60:\n",
    "#             #only add if theres content and its long enough\n",
    "#             count += 1\n",
    "            \n",
    "#     lst.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lst\n",
    "\n",
    "# lst[:0]\n",
    "\n",
    "# data = pd.read_csv('data.csv')\n",
    "\n",
    "# data.ix[:lst[0],'Hotels'] = 1\n",
    "# j = 2\n",
    "# for i in range(1,len(lst)):\n",
    "#     offset = sum(lst[:i])\n",
    "#     data.ix[offset:offset+lst[i],'Hotels'] = j\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.to_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = proj_base.getStandardData(numFiles=50)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keywords are calculated using the first 50 hotels, though entire data is 500 hotels. so first import 50 hotels, get keywords\n",
    "# and then import data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "proj_base.aspectSegmentationChiSquared(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for aspect in proj_base.seeds:\n",
    "    proj_base.aspect = aspect\n",
    "    train = proj_base.getTrainingData(data)\n",
    "    train.to_csv('train'+'_'.join(aspect.split('/'))+'.csv')\n",
    "    print aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('trainCheck in _ front desk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df['Review Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv('trainCleanliness.csv')\n",
    "# df2 = pd.read_csv('trainLocation.csv')\n",
    "# df2 = pd.read_csv('trainRooms.csv')\n",
    "# df2 = pd.read_csv('trainService.csv')\n",
    "# df2 = pd.read_csv('trainValue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandasql import *\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "q = '''\n",
    "select a.'Review Number' from df as a inner join df2 as b on a.'Review Number'\n",
    "= b.'Review Number'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pysqldf(q)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('allAspectTrainingData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainValue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "train['aspectSentences2'] = train['aspectSentences'].copy()\n",
    "train['aspectSentences'] = train['aspectSentences'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    16292\n",
       "4.0    12561\n",
       "3.0     6450\n",
       "2.0     3371\n",
       "1.0     2747\n",
       "Name: aspectRating, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['aspectRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    28853\n",
       "2.0     6450\n",
       "1.0     6118\n",
       "Name: aspectRating, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ix[train['aspectRating'] == 2, 'aspectRating'] = 1\n",
    "train.ix[train['aspectRating'] == 3, 'aspectRating'] = 2\n",
    "train.ix[(train['aspectRating'] == 4) | (train['aspectRating'] == 5), 'aspectRating'] = 3\n",
    "\n",
    "train['aspectRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mins = train['aspectRating'].value_counts().min()\n",
    "train_balanced = train.groupby(\"aspectRating\").apply(lambda x: x.sample(n=mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    6118\n",
       "2.0    6118\n",
       "1.0    6118\n",
       "Name: aspectRating, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced['aspectRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_balanced = train_balanced.apply(addSentimentScores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_senti = train_balanced.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_senti = min_max_scaler.fit_transform(X_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import sklearn.feature_extraction \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.naive_bayes import GaussianNBa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(review):  \n",
    "    review = review.encode('ascii',errors='ignore')\n",
    "    review = review.translate(None,string.punctuation)\n",
    "    words = nltk.tokenize.word_tokenize(review)\n",
    "    words = [nltk.stem.porter.PorterStemmer().stem(word) for word in words]\n",
    "    # stop words removed by vectorizer\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TfidVect = sklearn.feature_extraction.text.TfidfVectorizer(min_df=10, ngram_range=(1,2), tokenizer = custom_tokenizer,\n",
    "                                                      stop_words = nltk.corpus.stopwords.words('english'))\n",
    "X_tfidf = TfidVect.fit_transform(train_balanced['aspectSentences2'].tolist())\n",
    "X_tfidf = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newX = np.concatenate((X_tfidf,X_senti), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_clf = sklearn.svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "mse = 0\n",
    "corr = 0\n",
    "for i in range(5):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(newX, train_balanced['aspectRating'].tolist() )\n",
    "\n",
    "    pca = PCA(n_components=100)\n",
    "    pca.fit(X_train)\n",
    "    X_train2 = pca.transform(X_train)\n",
    "    X_test2 = pca.transform(X_test)\n",
    "\n",
    "#     clf.fit(X_train2,y_train)\n",
    "#     y_predicted = clf.predict(X_test2)\n",
    "    \n",
    "    lin_clf.fit(X_train2,y_train)\n",
    "    y_predicted = lin_clf.predict(X_test2)\n",
    "\n",
    "#     lin_clf.fit(X_train,y_train)\n",
    "#     y_predicted = lin_clf.predict(X_test)\n",
    "    \n",
    "    accuracy += (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "    mse +=  ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()\n",
    "    corr += np.corrcoef(y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.612856831554\n",
      "mse 0.601568969274\n",
      "corr [[ 1.          0.58016075]\n",
      " [ 0.58016075  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy {}'.format(accuracy/5.0)\n",
    "print 'mse {}'.format(mse/5.0)\n",
    "print 'corr {}'.format(corr/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "y_predicted = train_balanced['Overall'].tolist()\n",
    "y_test = train_balanced['aspectRating'].tolist()\n",
    "print 'accuracy'\n",
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print\n",
    "print 'mse'\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()\n",
    "print\n",
    "print 'corr'\n",
    "print np.corrcoef(y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_clf.fit(X_train2,y_train)\n",
    "y_predicted = lin_clf.predict(X_test2)\n",
    "\n",
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_top(clf):\n",
    "    top = []\n",
    "    for i in range(5):\n",
    "        top += list(np.argsort(clf.coef_[i])[-500:])\n",
    "        \n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_indices = select_top(lin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(top_indices)[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2 = np.concatenate((X_train[:,0:5], X_train[:,top_indices]), axis=1)\n",
    "X_test2 = np.concatenate((X_test[:,0:5], X_test[:,top_indices]), axis=1)\n",
    "\n",
    "lin_clf.fit(X_train2,y_train)\n",
    "y_predicted = lin_clf.predict(X_test2)\n",
    "\n",
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.corrcoef(y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_balanced['aspectRating'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TfidVect = sklearn.feature_extraction.text.TfidfVectorizer(min_df=10, ngram_range=(1,1), tokenizer = custom_tokenizer,\n",
    "                                                      stop_words = nltk.corpus.stopwords.words('english'))\n",
    "X_tfidf = TfidVect.fit_transform(train_balanced['aspectSentences'].tolist())\n",
    "X_tfidf = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_balanced['aspectRating'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_clf = sklearn.svm.LinearSVC()\n",
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newX, train_balanced['aspectRating'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lin_clf, X_tfidf, train_balanced['aspectRating'].tolist(), cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\"{0:.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[501 115  31  13  28]\n",
      " [273 180 109  39  73]\n",
      " [109 100 199 124 157]\n",
      " [ 40  60 125 172 277]\n",
      " [ 56  39  58 140 416]]\n",
      "Normalized confusion matrix\n",
      "[[ 0.72819767  0.16715116  0.04505814  0.01889535  0.04069767]\n",
      " [ 0.40504451  0.26706231  0.16172107  0.0578635   0.10830861]\n",
      " [ 0.15820029  0.14513788  0.28882438  0.17997097  0.22786647]\n",
      " [ 0.05934718  0.08902077  0.18545994  0.25519288  0.41097923]\n",
      " [ 0.07898449  0.05500705  0.08180536  0.19746121  0.58674189]]\n"
     ]
    }
   ],
   "source": [
    "# Test confusion matrix function\n",
    "y_pred = y_predicted\n",
    "class_names=range(1,6)\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
