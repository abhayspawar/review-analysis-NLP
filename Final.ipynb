{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "from Sentiment_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import proj_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "file_list = sorted(listdir('./Review_Texts/'))\n",
    "for i in range(500):\n",
    "    filename = file_list[i]\n",
    "#     intColumns = ['No. Reader', 'No. Helpful', 'Cleanliness','Check in / front desk', 'Value', 'Overall', 'Service', 'Business service', 'Rooms', 'Location']\n",
    "    characterThreshold = 60\n",
    "    with open('./Review_Texts/'+filename, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        \n",
    "        #print(repr(content))\n",
    "    if content.count(\"\\r\") > 0:\n",
    "        reviews = content.split(\"\\r\\n\\r\\n\")\n",
    "    else:\n",
    "        reviews = content.split(\"\\n\\n\")\n",
    "    \n",
    "    count = 0\n",
    "    for r in reviews:\n",
    "        thisReview = {}\n",
    "        splt = r.split(\"\\n\")\n",
    "        for s in splt:\n",
    "            for c in ['Content']:\n",
    "                if \"<\"+c+\">\" in s:\n",
    "                    value = s.replace('<'+c+'>', '')\n",
    "                    if c in intColumns:\n",
    "                        value = int(value)\n",
    "                    if value == -1: #we dont want -1 as this is going to mess up averaging, take np.nan\n",
    "                        value = np.nan\n",
    "\n",
    "                    if c == \"Content\":\n",
    "                        value = unidecode(unicode(value.lower(), encoding=\"utf-8\"))\n",
    "\n",
    "                    thisReview[c] = value\n",
    "                    \n",
    "        if not thisReview.get(\"Content\") == None and len(thisReview[\"Content\"]) > 60:\n",
    "            #only add if theres content and its long enough\n",
    "            count += 1\n",
    "            \n",
    "    lst.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124,\n",
       " 145,\n",
       " 32,\n",
       " 131,\n",
       " 64,\n",
       " 123,\n",
       " 81,\n",
       " 73,\n",
       " 137,\n",
       " 194,\n",
       " 117,\n",
       " 111,\n",
       " 56,\n",
       " 79,\n",
       " 284,\n",
       " 86,\n",
       " 149,\n",
       " 121,\n",
       " 63,\n",
       " 123,\n",
       " 41,\n",
       " 19,\n",
       " 67,\n",
       " 54,\n",
       " 124,\n",
       " 196,\n",
       " 183,\n",
       " 63,\n",
       " 98,\n",
       " 23,\n",
       " 36,\n",
       " 62,\n",
       " 34,\n",
       " 41,\n",
       " 65,\n",
       " 42,\n",
       " 27,\n",
       " 29,\n",
       " 57,\n",
       " 65,\n",
       " 26,\n",
       " 37,\n",
       " 26,\n",
       " 32,\n",
       " 56,\n",
       " 110,\n",
       " 23,\n",
       " 21,\n",
       " 43,\n",
       " 15,\n",
       " 37,\n",
       " 148,\n",
       " 122,\n",
       " 86,\n",
       " 199,\n",
       " 77,\n",
       " 61,\n",
       " 116,\n",
       " 33,\n",
       " 32,\n",
       " 52,\n",
       " 41,\n",
       " 100,\n",
       " 156,\n",
       " 33,\n",
       " 322,\n",
       " 200,\n",
       " 274,\n",
       " 21,\n",
       " 99,\n",
       " 83,\n",
       " 157,\n",
       " 112,\n",
       " 82,\n",
       " 228,\n",
       " 675,\n",
       " 92,\n",
       " 24,\n",
       " 49,\n",
       " 31,\n",
       " 141,\n",
       " 183,\n",
       " 244,\n",
       " 192,\n",
       " 128,\n",
       " 142,\n",
       " 71,\n",
       " 209,\n",
       " 138,\n",
       " 152,\n",
       " 83,\n",
       " 46,\n",
       " 154,\n",
       " 214,\n",
       " 36,\n",
       " 848,\n",
       " 85,\n",
       " 104,\n",
       " 33,\n",
       " 41,\n",
       " 45,\n",
       " 112,\n",
       " 89,\n",
       " 67,\n",
       " 56,\n",
       " 92,\n",
       " 77,\n",
       " 130,\n",
       " 128,\n",
       " 160,\n",
       " 375,\n",
       " 82,\n",
       " 102,\n",
       " 20,\n",
       " 37,\n",
       " 63,\n",
       " 27,\n",
       " 336,\n",
       " 28,\n",
       " 38,\n",
       " 186,\n",
       " 90,\n",
       " 13,\n",
       " 60,\n",
       " 58,\n",
       " 20,\n",
       " 66,\n",
       " 76,\n",
       " 70,\n",
       " 23,\n",
       " 155,\n",
       " 61,\n",
       " 28,\n",
       " 27,\n",
       " 43,\n",
       " 94,\n",
       " 28,\n",
       " 148,\n",
       " 345,\n",
       " 51,\n",
       " 89,\n",
       " 26,\n",
       " 79,\n",
       " 60,\n",
       " 105,\n",
       " 397,\n",
       " 255,\n",
       " 443,\n",
       " 51,\n",
       " 563,\n",
       " 44,\n",
       " 182,\n",
       " 225,\n",
       " 113,\n",
       " 634,\n",
       " 921,\n",
       " 1397,\n",
       " 250,\n",
       " 418,\n",
       " 530,\n",
       " 89,\n",
       " 373,\n",
       " 98,\n",
       " 393,\n",
       " 142,\n",
       " 1030,\n",
       " 446,\n",
       " 597,\n",
       " 395,\n",
       " 291,\n",
       " 352,\n",
       " 71,\n",
       " 182,\n",
       " 167,\n",
       " 47,\n",
       " 55,\n",
       " 81,\n",
       " 23,\n",
       " 50,\n",
       " 95,\n",
       " 255,\n",
       " 77,\n",
       " 29,\n",
       " 49,\n",
       " 34,\n",
       " 41,\n",
       " 165,\n",
       " 26,\n",
       " 43,\n",
       " 24,\n",
       " 21,\n",
       " 50,\n",
       " 45,\n",
       " 149,\n",
       " 343,\n",
       " 53,\n",
       " 72,\n",
       " 20,\n",
       " 32,\n",
       " 54,\n",
       " 218,\n",
       " 91,\n",
       " 56,\n",
       " 62,\n",
       " 95,\n",
       " 21,\n",
       " 49,\n",
       " 44,\n",
       " 87,\n",
       " 115,\n",
       " 176,\n",
       " 222,\n",
       " 171,\n",
       " 255,\n",
       " 110,\n",
       " 104,\n",
       " 34,\n",
       " 87,\n",
       " 125,\n",
       " 149,\n",
       " 68,\n",
       " 245,\n",
       " 68,\n",
       " 50,\n",
       " 91,\n",
       " 266,\n",
       " 49,\n",
       " 239,\n",
       " 37,\n",
       " 53,\n",
       " 72,\n",
       " 135,\n",
       " 88,\n",
       " 65,\n",
       " 47,\n",
       " 39,\n",
       " 176,\n",
       " 165,\n",
       " 504,\n",
       " 357,\n",
       " 77,\n",
       " 73,\n",
       " 38,\n",
       " 80,\n",
       " 110,\n",
       " 165,\n",
       " 65,\n",
       " 128,\n",
       " 69,\n",
       " 49,\n",
       " 63,\n",
       " 53,\n",
       " 494,\n",
       " 55,\n",
       " 34,\n",
       " 83,\n",
       " 36,\n",
       " 47,\n",
       " 50,\n",
       " 126,\n",
       " 93,\n",
       " 95,\n",
       " 50,\n",
       " 106,\n",
       " 103,\n",
       " 151,\n",
       " 55,\n",
       " 46,\n",
       " 70,\n",
       " 86,\n",
       " 108,\n",
       " 54,\n",
       " 50,\n",
       " 71,\n",
       " 56,\n",
       " 68,\n",
       " 50,\n",
       " 56,\n",
       " 74,\n",
       " 26,\n",
       " 164,\n",
       " 26,\n",
       " 26,\n",
       " 45,\n",
       " 50,\n",
       " 53,\n",
       " 58,\n",
       " 41,\n",
       " 71,\n",
       " 89,\n",
       " 47,\n",
       " 84,\n",
       " 161,\n",
       " 24,\n",
       " 27,\n",
       " 21,\n",
       " 77,\n",
       " 92,\n",
       " 30,\n",
       " 35,\n",
       " 116,\n",
       " 56,\n",
       " 64,\n",
       " 47,\n",
       " 138,\n",
       " 28,\n",
       " 72,\n",
       " 32,\n",
       " 126,\n",
       " 36,\n",
       " 66,\n",
       " 83,\n",
       " 56,\n",
       " 62,\n",
       " 71,\n",
       " 83,\n",
       " 110,\n",
       " 126,\n",
       " 103,\n",
       " 53,\n",
       " 73,\n",
       " 183,\n",
       " 23,\n",
       " 106,\n",
       " 92,\n",
       " 113,\n",
       " 291,\n",
       " 61,\n",
       " 63,\n",
       " 51,\n",
       " 41,\n",
       " 48,\n",
       " 128,\n",
       " 108,\n",
       " 33,\n",
       " 43,\n",
       " 41,\n",
       " 123,\n",
       " 88,\n",
       " 39,\n",
       " 60,\n",
       " 49,\n",
       " 310,\n",
       " 68,\n",
       " 67,\n",
       " 74,\n",
       " 412,\n",
       " 1078,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 107,\n",
       " 17,\n",
       " 382,\n",
       " 343,\n",
       " 164,\n",
       " 379,\n",
       " 124,\n",
       " 199,\n",
       " 202,\n",
       " 148,\n",
       " 435,\n",
       " 126,\n",
       " 40,\n",
       " 47,\n",
       " 30,\n",
       " 270,\n",
       " 202,\n",
       " 40,\n",
       " 96,\n",
       " 116,\n",
       " 304,\n",
       " 284,\n",
       " 148,\n",
       " 59,\n",
       " 38,\n",
       " 33,\n",
       " 35,\n",
       " 33,\n",
       " 49,\n",
       " 54,\n",
       " 127,\n",
       " 306,\n",
       " 27,\n",
       " 41,\n",
       " 195,\n",
       " 59,\n",
       " 221,\n",
       " 123,\n",
       " 605,\n",
       " 895,\n",
       " 199,\n",
       " 2337,\n",
       " 79,\n",
       " 30,\n",
       " 113,\n",
       " 400,\n",
       " 190,\n",
       " 49,\n",
       " 36,\n",
       " 185,\n",
       " 85,\n",
       " 60,\n",
       " 44,\n",
       " 175,\n",
       " 84,\n",
       " 29,\n",
       " 26,\n",
       " 37,\n",
       " 40,\n",
       " 264,\n",
       " 34,\n",
       " 97,\n",
       " 40,\n",
       " 24,\n",
       " 351,\n",
       " 32,\n",
       " 91,\n",
       " 224,\n",
       " 364,\n",
       " 113,\n",
       " 28,\n",
       " 135,\n",
       " 38,\n",
       " 52,\n",
       " 195,\n",
       " 38,\n",
       " 35,\n",
       " 73,\n",
       " 33,\n",
       " 48,\n",
       " 185,\n",
       " 374,\n",
       " 25,\n",
       " 110,\n",
       " 104,\n",
       " 49,\n",
       " 67,\n",
       " 167,\n",
       " 256,\n",
       " 77,\n",
       " 109,\n",
       " 281,\n",
       " 112,\n",
       " 135,\n",
       " 58,\n",
       " 55,\n",
       " 18,\n",
       " 75,\n",
       " 90,\n",
       " 65,\n",
       " 46,\n",
       " 64,\n",
       " 61,\n",
       " 152,\n",
       " 46,\n",
       " 37,\n",
       " 43,\n",
       " 173,\n",
       " 161,\n",
       " 134,\n",
       " 48,\n",
       " 51,\n",
       " 75,\n",
       " 47,\n",
       " 34,\n",
       " 57,\n",
       " 61,\n",
       " 85,\n",
       " 57,\n",
       " 48,\n",
       " 75,\n",
       " 118,\n",
       " 40,\n",
       " 266,\n",
       " 43,\n",
       " 38,\n",
       " 47,\n",
       " 131,\n",
       " 57,\n",
       " 97,\n",
       " 186,\n",
       " 64,\n",
       " 89,\n",
       " 298,\n",
       " 120,\n",
       " 117,\n",
       " 169,\n",
       " 157,\n",
       " 97,\n",
       " 100,\n",
       " 213,\n",
       " 33,\n",
       " 78,\n",
       " 93,\n",
       " 123,\n",
       " 328,\n",
       " 145,\n",
       " 23,\n",
       " 85]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.ix[:lst[0],'Hotels'] = 1\n",
    "j = 2\n",
    "for i in range(1,len(lst)):\n",
    "    offset = sum(lst[:i])\n",
    "    data.ix[offset:offset+lst[i],'Hotels'] = j\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4008, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Hilobb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chianti_girl24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loved the monaco! staff was amazing, with a sm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service Business service          Author  \\\n",
       "0    5.0  Dec 23, 2008       5.0      5.0              NaN     selizabethm   \n",
       "1    4.0  Nov 13, 2008       5.0      5.0              NaN       IndieLady   \n",
       "2    4.0  Nov 11, 2008       3.0      NaN                4          Hilobb   \n",
       "3    5.0   Nov 4, 2008       5.0      5.0                5  Chianti_girl24   \n",
       "4    NaN  Oct 18, 2008       NaN      NaN              NaN      hothearted   \n",
       "\n",
       "   Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0                    5.0         NaN          5.0   \n",
       "1                    5.0         NaN          4.0   \n",
       "2                    5.0         NaN          4.0   \n",
       "3                    5.0         NaN          5.0   \n",
       "4                    NaN           2          NaN   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  wonderful time- even with the snow! what a gre...    4.0        NaN   \n",
       "1  lovely hotel, unique decor, friendly front des...    5.0        NaN   \n",
       "2  nice hotel, expensive parking we got a good de...    4.0        NaN   \n",
       "3  fabulous hotel location and service are great....    5.0        NaN   \n",
       "4  loved the monaco! staff was amazing, with a sm...    NaN          2   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = proj_base.getStandardData(numFiles=50)\n",
    "# print(data.shape)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64152, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keywords are calculated using the first 50 hotels, though entire data is 500 hotels. so first import 50 hotels, get keywords\n",
    "# and then import data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business service': ['business',\n",
       "  'center',\n",
       "  'computer',\n",
       "  'internet',\n",
       "  u'access',\n",
       "  u'convention',\n",
       "  u'wireless',\n",
       "  u'free',\n",
       "  u'westlake',\n",
       "  u'fitness',\n",
       "  u'wifi',\n",
       "  u'printer',\n",
       "  u'connection'],\n",
       " 'Check in / front desk': ['stuff',\n",
       "  'check',\n",
       "  'help',\n",
       "  'reservation',\n",
       "  u'upon',\n",
       "  u'early',\n",
       "  u'desk',\n",
       "  u'front',\n",
       "  u'clerk',\n",
       "  u'arrival',\n",
       "  u'staff',\n",
       "  u'told',\n",
       "  u'called'],\n",
       " 'Cleanliness': ['clean',\n",
       "  'dirty',\n",
       "  'maintain',\n",
       "  'smell',\n",
       "  u'comfortable',\n",
       "  u'room',\n",
       "  u'rooms',\n",
       "  u'bed',\n",
       "  u'small',\n",
       "  u'beds',\n",
       "  u'king',\n",
       "  u'bathroom',\n",
       "  u'floor'],\n",
       " 'Location': ['location',\n",
       "  'traffic',\n",
       "  'minute',\n",
       "  'restaurant',\n",
       "  u'great',\n",
       "  u'good',\n",
       "  u'market',\n",
       "  u'pike',\n",
       "  u'place',\n",
       "  u'value',\n",
       "  u'shopping',\n",
       "  u'walk',\n",
       "  u'downtown'],\n",
       " 'Rooms': ['room',\n",
       "  'suite',\n",
       "  'view',\n",
       "  'bed',\n",
       "  u'comfortable',\n",
       "  u'floor',\n",
       "  u'king',\n",
       "  u'clean',\n",
       "  u'beds',\n",
       "  u'spacious',\n",
       "  u'large',\n",
       "  u'size',\n",
       "  u'bathroom'],\n",
       " 'Service': ['service',\n",
       "  'food',\n",
       "  'breakfast',\n",
       "  'buffet',\n",
       "  u'continental',\n",
       "  u'customer',\n",
       "  u'restaurant',\n",
       "  u'good',\n",
       "  u'excellent',\n",
       "  u'ate',\n",
       "  u'location',\n",
       "  u'value',\n",
       "  u'dinner'],\n",
       " 'Value': ['value',\n",
       "  'price',\n",
       "  'quality',\n",
       "  'worth',\n",
       "  u'money',\n",
       "  u'good',\n",
       "  u'great',\n",
       "  u'location',\n",
       "  u'hotel',\n",
       "  u'deal',\n",
       "  u'seattle',\n",
       "  u'downtown',\n",
       "  u'stayed']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_base.aspectSegmentationChiSquared(data, min_freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service\n",
      "Business service\n",
      "Cleanliness\n",
      "Check in / front desk\n",
      "Value\n",
      "Rooms\n",
      "Location\n"
     ]
    }
   ],
   "source": [
    "for aspect in proj_base.seeds:\n",
    "    proj_base.aspect = aspect\n",
    "    train = proj_base.getTrainingData(data)\n",
    "    train.to_csv('train'+'_'.join(aspect.split('/'))+'.csv')\n",
    "    print aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainRooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aspectRating</th>\n",
       "      <th>aspectSentences</th>\n",
       "      <th>Content</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['from the goldfish in the room (which my daug...</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['the decor at the kimpton hotels is always un...</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['we were a little disappointed by the (non-ex...</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['the valet was a doll, the front desk got me ...</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['well to start off i booked a suite and paid ...</td>\n",
       "      <td>ok, but nothing special for the $$ they charge...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  aspectRating  \\\n",
       "0           0           5.0   \n",
       "1           1           4.0   \n",
       "2           2           4.0   \n",
       "3           3           5.0   \n",
       "4           5           3.0   \n",
       "\n",
       "                                     aspectSentences  \\\n",
       "0  ['from the goldfish in the room (which my daug...   \n",
       "1  ['the decor at the kimpton hotels is always un...   \n",
       "2  ['we were a little disappointed by the (non-ex...   \n",
       "3  ['the valet was a doll, the front desk got me ...   \n",
       "4  ['well to start off i booked a suite and paid ...   \n",
       "\n",
       "                                             Content  Overall  \n",
       "0  wonderful time- even with the snow! what a gre...      5.0  \n",
       "1  lovely hotel, unique decor, friendly front des...      4.0  \n",
       "2  nice hotel, expensive parking we got a good de...      4.0  \n",
       "3  fabulous hotel location and service are great....      5.0  \n",
       "4  ok, but nothing special for the $$ they charge...      2.0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "train['aspectSentences2'] = train['aspectSentences'].copy()\n",
    "train['aspectSentences'] = train['aspectSentences'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    13928\n",
       "4.0    12287\n",
       "3.0     5748\n",
       "2.0     3227\n",
       "1.0     2074\n",
       "Name: aspectRating, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['aspectRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.ix[train['aspectRating'] == 3, 'aspectRating'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.ix[(train['aspectRating'] == 4) | (train['aspectRating'] == 5), 'aspectRating'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    26215\n",
       "2.0     8975\n",
       "1.0     2074\n",
       "Name: aspectRating, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['aspectRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mins = train['aspectRating'].value_counts().min()\n",
    "train_balanced = train.groupby(\"aspectRating\").apply(lambda x: x.sample(n=mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_balanced = train_balanced.apply(addSentimentScores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_senti = train_balanced.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>score_basic_pos</th>\n",
       "      <th>score_basic_neg</th>\n",
       "      <th>score_basic</th>\n",
       "      <th>score_pos</th>\n",
       "      <th>score_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspectRating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th>29097</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31757</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    score  score_basic_pos  score_basic_neg  score_basic  \\\n",
       "aspectRating                                                               \n",
       "1.0          29097   -3.0                2               -3           -1   \n",
       "             31757    9.0                9                0            9   \n",
       "             8365     1.0                3               -2            1   \n",
       "             23976    0.0                3               -3            0   \n",
       "             5594    -1.0                1               -2           -1   \n",
       "\n",
       "                    score_pos  score_neg  \n",
       "aspectRating                              \n",
       "1.0          29097        0.0       -3.0  \n",
       "             31757        9.0        0.0  \n",
       "             8365         3.0       -2.0  \n",
       "             23976        3.0       -3.0  \n",
       "             5594         1.0       -2.0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_senti = min_max_scaler.fit_transform(X_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import sklearn.feature_extraction \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.naive_bayes import GaussianNBa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(review):  \n",
    "    review = review.encode('ascii',errors='ignore')\n",
    "    review = review.translate(None,string.punctuation)\n",
    "    words = nltk.tokenize.word_tokenize(review)\n",
    "    words = [nltk.stem.porter.PorterStemmer().stem(word) for word in words]\n",
    "    # stop words removed by vectorizer\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TfidVect = sklearn.feature_extraction.text.TfidfVectorizer(min_df=10, ngram_range=(1,2), tokenizer = custom_tokenizer,\n",
    "                                                      stop_words = nltk.corpus.stopwords.words('english'))\n",
    "X_tfidf = TfidVect.fit_transform(train_balanced['aspectSentences2'].tolist())\n",
    "X_tfidf = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newX = np.concatenate((X_tfidf,X_senti), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_clf = sklearn.svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609254498715\n",
      "0.516066838046\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newX, train_balanced['aspectRating'].tolist() )\n",
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)\n",
    "\n",
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train)\n",
    "X_train2 = pca.transform(X_train)\n",
    "X_test2 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657455012853\n",
      "0.460154241645\n"
     ]
    }
   ],
   "source": [
    "lin_clf.fit(X_train2,y_train)\n",
    "y_predicted = lin_clf.predict(X_test2)\n",
    "\n",
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_top(clf):\n",
    "    top = []\n",
    "    for i in range(5):\n",
    "        top += list(np.argsort(clf.coef_[i])[-500:])\n",
    "        \n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-977f53d9120c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtop_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_top\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlin_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-201-7d3531a48484>\u001b[0m in \u001b[0;36mselect_top\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtop\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "top_indices = select_top(lin_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7486 is out of bounds for axis 1 with size 7469",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-93fde6f8032c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlin_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7486 is out of bounds for axis 1 with size 7469"
     ]
    }
   ],
   "source": [
    "X_train2 = np.concatenate((X_train[:,0:5], X_train[:,top_indices]), axis=1)\n",
    "X_test2 = np.concatenate((X_test[:,0:5], X_test[:,top_indices]), axis=1)\n",
    "\n",
    "lin_clf.fit(X_train2,y_train)\n",
    "y_predicted = lin_clf.predict(X_test2)\n",
    "\n",
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_balanced['aspectRating'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (pd.Series(y_predicted) == pd.Series(y_test)).mean()\n",
    "print ((pd.Series(y_predicted)-pd.Series(y_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TfidVect = sklearn.feature_extraction.text.TfidfVectorizer(min_df=10, ngram_range=(1,1), tokenizer = custom_tokenizer,\n",
    "                                                      stop_words = nltk.corpus.stopwords.words('english'))\n",
    "X_tfidf = TfidVect.fit_transform(train_balanced['aspectSentences'].tolist())\n",
    "X_tfidf = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_balanced['aspectRating'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_clf = sklearn.svm.LinearSVC()\n",
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "(pd.Series(y_predicted) == pd.Series(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lin_clf, X_tfidf, train_balanced['aspectRating'].tolist(), cv = 5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\"{0:.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test confusion matrix function\n",
    "y_pred = y_predicted\n",
    "class_names=range(1,6)\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
