{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import networkx as nx\n",
    "import proj_base\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "#tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as scpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = proj_base.getBlankFrame()\n",
    "#data = proj_base.addFileToData('./Review_Texts/hotel_100504.dat', data, ) \n",
    "data = proj_base.addFileToData('./Review_Texts/hotel_72572.dat', data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Jan 6, 2009</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>everywhereman2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>old seattle getaway this was old world excelle...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 14, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KGBT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wow, what charm! as a travel agent, i've staye...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec 1, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Marilyn1949</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great location for sporting events we attend s...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 28, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MissViolet105</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pioneer square bw fine choice we chose bw pion...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 25, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fallriverma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>quality hotel at great price very clean. free ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service  Business service          Author  \\\n",
       "0    5.0   Jan 6, 2009       5.0      5.0               5.0  everywhereman2   \n",
       "1    5.0  Dec 14, 2008       5.0      NaN               4.0            KGBT   \n",
       "2    4.0   Dec 1, 2008       5.0      5.0               5.0     Marilyn1949   \n",
       "3    5.0  Nov 28, 2008       5.0      5.0               2.0   MissViolet105   \n",
       "4    5.0  Nov 25, 2008       5.0      5.0               5.0     fallriverma   \n",
       "\n",
       "   Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0                    5.0         NaN          5.0   \n",
       "1                    4.0         NaN          5.0   \n",
       "2                    5.0         NaN          5.0   \n",
       "3                    5.0         NaN          5.0   \n",
       "4                    5.0         NaN          5.0   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  old seattle getaway this was old world excelle...    5.0        NaN   \n",
       "1  wow, what charm! as a travel agent, i've staye...    4.0        NaN   \n",
       "2  great location for sporting events we attend s...    4.0        NaN   \n",
       "3  pioneer square bw fine choice we chose bw pion...    5.0        NaN   \n",
       "4  quality hotel at great price very clean. free ...    5.0        NaN   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      5.0  \n",
       "2      4.0  \n",
       "3      4.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = data.shape[0]\n",
    "print(nodes)\n",
    "data.head()\n",
    "#len(set(data[\"Author\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "#word2vec takes a list of lists, where each internal list is a BOW\n",
    "\n",
    "\n",
    "def review2sentences(review, tokenizer, remove_stopwords=True):\n",
    "    #split each review into sentences\n",
    "    raw_sent = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    sentences = []\n",
    "    for s in raw_sent:\n",
    "        if len(s) > 0 :\n",
    "            sentences.append(review2wordlist(s, remove_stopwords))\n",
    "            \n",
    "    return sentences\n",
    "\n",
    "\n",
    "def review2wordlist(review_text, remove_stopwords=True):\n",
    "    #split the given text into BOW\n",
    "    \n",
    "\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return(words)\n",
    "\n",
    "\n",
    "for review in data[\"Content\"]:\n",
    "    sentences += review2sentences(review, tokenizer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "#BUILD WORD2Vec infrastructure\n",
    "\n",
    "num_features = 100\n",
    "min_word_count = 40\n",
    "num_workers = 2\n",
    "context = 2\n",
    "downsampling = 1e-3\n",
    "\n",
    "from gensim.models import word2vec\n",
    "print(\"training\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features)\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    #given a list of words and the pre-trained word model return a feature vector\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    \n",
    "    nwords = 0\n",
    "    index2word_set = set(model.index2word)\n",
    "    \n",
    "    \n",
    "    #get the mean vector for each review\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        if w in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec, model[w])\n",
    "            \n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVec(reviews, model, num_features):\n",
    "    #get average feature vec for list of bag of words\n",
    "    count = 0\n",
    "    reviewFeatureVec = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "    \n",
    "    for r in reviews:\n",
    "        if count % 1000 == 0:\n",
    "            print(\"at review\", count)\n",
    "        #for each review add the feature vec\n",
    "        reviewFeatureVec[count] = makeFeatureVec(r, model, num_features)\n",
    "        count += 1\n",
    "        \n",
    "    return reviewFeatureVec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['old', 'seattle', 'getaway', 'old', 'world', 'excellence', 'best', 'place', 'stay', 'visiting', 'historical', 'area', 'seattle', 'right', 'water', 'front', 'near', 'ferry', 'great', 'sea', 'food', 'restraunts', 'still', 'walking', 'distance', 'great', 'blues', 'jazz', 'music', 'staff', 'hotel', 'excellent', 'make', 'feel', 'right', 'home', 'breakfast', 'great', 'nt', 'travel', 'far', 'good', 'cup', 'joe', 'light', 'meal', 'start', 'adventurous', 'day', 'one', 'beautifull', 'city', 'america', 'hotel', 'area', 'makes', 'easy', 'get', 'place', 'want', 'go', 'still', 'find', 'way', 'back', 'highly', 'recomend', 'hotel', 'next', 'visit', 'seattle']\n",
      "[-0.00182859  0.0010434  -0.00205694  0.00189076 -0.00419966 -0.00039751\n",
      "  0.00052745  0.00035069 -0.00148416 -0.00143551 -0.00164039 -0.00111382\n",
      "  0.00625432  0.00043604 -0.0015831  -0.00059523  0.00135195 -0.0031035\n",
      "  0.00150067 -0.00045331  0.00095373 -0.0003382   0.00205024 -0.00042875\n",
      " -0.00104579 -0.00227782  0.00237869  0.0018574   0.00116588 -0.00393189\n",
      " -0.00547995  0.00064348  0.00233076 -0.00440565 -0.00103422 -0.00072764\n",
      "  0.00315759 -0.00298515  0.00193591 -0.00036613  0.00204982 -0.00101827\n",
      "  0.00073761  0.00315372  0.00362761 -0.00052053  0.00209532 -0.00207983\n",
      " -0.00169814  0.00474057 -0.00624264  0.00285811  0.00395289  0.00160012\n",
      "  0.00028881  0.00175878  0.00022793 -0.00128279 -0.00157551  0.00314511\n",
      " -0.00274726 -0.00448141 -0.00064844  0.0028722   0.00184325  0.00093173\n",
      " -0.00202807 -0.0002288  -0.00318209 -0.00119426  0.00265764 -0.00415416\n",
      "  0.00133349  0.00069304  0.00209279 -0.001855    0.0003964   0.00026618\n",
      "  0.00080062  0.00083514 -0.00082617  0.0008184  -0.00310365  0.00182912\n",
      " -0.00466867  0.00116202  0.00154159  0.00056986 -0.00128967  0.00058883\n",
      " -0.00106771  0.00075287 -0.00166826  0.00201422  0.00187807 -0.00054147\n",
      "  0.00139045 -0.00239752  0.00077467 -0.00357037]\n"
     ]
    }
   ],
   "source": [
    "rev1 = data[\"Content\"][0]\n",
    "rev12words = review2wordlist(rev1, tokenizer)\n",
    "print(rev12words)\n",
    "rev1avg = makeFeatureVec(rev12words, model, num_features)\n",
    "print(rev1avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GET HARD TRUTH RATINGS\n",
    "\n",
    "aspect=\"Location\"\n",
    "\n",
    "def filterHardTruthForAspect(data, aspect):\n",
    "    #give data points that have hard truth ratings\n",
    "    return  data[pd.notnull(data[aspect])]\n",
    "\n",
    "justLoc = filterHardTruthForAspect(data, aspect)\n",
    "justLoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def buildGraph(data, sim):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    neighborsForNodes = 6\n",
    "    nodes = data.shape[0]\n",
    "    # build nodes\n",
    "    for i in range(nodes):\n",
    "        rev = data.loc[i]\n",
    "        content = rev[\"Content\"]\n",
    "        #todo only add relevant sentences or take whole content?\n",
    "        \n",
    "        G.add_node(i, {'author' : rev[\"Author\"], 'content' :content})\n",
    "        \n",
    "        #if i has a hard-truth rating add a node with that dongle\n",
    "        #if rev[aspect] != np.nan:\n",
    "        #    G.add_node(i+nodes, truth=True, rating=rev[aspect])\n",
    "        #    G.add_edge(i, i+nodes, weight=1)\n",
    "    \n",
    "    # build edges\n",
    "    sims = buildSimilarityMatrix(data)\n",
    "    for i in range(nodes):\n",
    "        for j in range(nodes):\n",
    "            G.add_edge(i, j, weight=sims[i][j])\n",
    "    \n",
    "    \n",
    "\n",
    "    # add separate learner scores\n",
    "    \n",
    "    return G\n",
    "\n",
    "def howSimilar(r1, r2):\n",
    "    #use word2vec cosine similarity\n",
    "    \n",
    "    rev2words = review2wordlist(r1, tokenizer)\n",
    "    rev1vec = makeFeatureVec(rev2words, model, num_features)\n",
    "    revj2words = review2wordlist(r2)\n",
    "    rev2vec = makeFeatureVec(revj2words, model, num_features)\n",
    "    return scpd.cosine(rev1vec, rev2vec)\n",
    "\n",
    "\n",
    "def buildSimilarityMatrix(data):\n",
    "    \n",
    "    similar = [[0]*nodes for i in range(nodes)]\n",
    "    \n",
    "    for i in range(nodes):\n",
    "        dati = data.loc[i][\"Content\"]\n",
    "        \n",
    "        for j in range(nodes):\n",
    "            if i != j:\n",
    "                datj = data.loc[j][\"Content\"]\n",
    "               \n",
    "                similar[i][j] = howSimilar(dati, data.loc[j][\"Content\"])\n",
    "                \n",
    "    return similar\n",
    "\n",
    "\n",
    "def getRatings(graph):\n",
    "    #minimize loss ratings over the graph\n",
    "    \n",
    "    \n",
    "    #for edge in graph\n",
    "    #   loss = \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "similarities = buildSimilarityMatrix(data)\n",
    "g = buildGraph(data, similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045377495137383539"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev2words = review2wordlist(data[\"Content\"][0], tokenizer)\n",
    "rev1vec = makeFeatureVec(rev2words, model, num_features)\n",
    "revj2words = review2wordlist(data[\"Content\"][1])\n",
    "rev2vec = makeFeatureVec(revj2words, model, num_features)\n",
    "scpd.cosine(rev1vec, rev2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nx.get_edge_attributes(g, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nx.draw(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "\n",
    "#do svm classification\n",
    "#need to split data into hard-truth train and predict\n",
    "#not sure how were actually going to do this. Hard-truth ratings are needed to train the model right?\n",
    "#but we'll also need to have some to test the results\n",
    "#so probably going to need to have a lot of reviews\n",
    "\n",
    "#train = sample of data with hard rating\n",
    "\n",
    "trainDataVecs = getAvgFeatureVec(train, model, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
