{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "import pprint as pp\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import time\n",
    "import proj_base\n",
    "#data from http://times.cs.uiuc.edu/~wang296/Data/\n",
    "files = os.listdir('./Review_Texts')\n",
    "#print(os.listdir('./Review_Texts'))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 13)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proj_base.getStandardData(numFiles=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Hilobb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chianti_girl24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loved the monaco! staff was amazing, with a sm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service Business service          Author  \\\n",
       "0    5.0  Dec 23, 2008       5.0      5.0              NaN     selizabethm   \n",
       "1    4.0  Nov 13, 2008       5.0      5.0              NaN       IndieLady   \n",
       "2    4.0  Nov 11, 2008       3.0      NaN                4          Hilobb   \n",
       "3    5.0   Nov 4, 2008       5.0      5.0                5  Chianti_girl24   \n",
       "4    NaN  Oct 18, 2008       NaN      NaN              NaN      hothearted   \n",
       "\n",
       "   Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0                    5.0         NaN          5.0   \n",
       "1                    5.0         NaN          4.0   \n",
       "2                    5.0         NaN          4.0   \n",
       "3                    5.0         NaN          5.0   \n",
       "4                    NaN           2          NaN   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  wonderful time- even with the snow! what a gre...    4.0        NaN   \n",
       "1  lovely hotel, unique decor, friendly front des...    5.0        NaN   \n",
       "2  nice hotel, expensive parking we got a good de...    4.0        NaN   \n",
       "3  fabulous hotel location and service are great....    5.0        NaN   \n",
       "4  loved the monaco! staff was amazing, with a sm...    NaN          2   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean of int columns\n",
    "data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"Content\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating the vocab of all the words\n",
    "\n",
    "def lintWord(w):\n",
    "    regex = re.compile(r'(,|\\(|\\)|!|:|$|\\.)')\n",
    "    w = re.sub(regex, '', w)\n",
    "    return w\n",
    "\n",
    "\n",
    "allWords = \"\"\n",
    "for r in data[\"Content\"]:\n",
    "    #add word to big content string\n",
    "    allWords += r + \" \"\n",
    "    \n",
    "#split the string at spaces, keep only unique\n",
    "words = set(allWords.split(\" \"))\n",
    "\n",
    "\n",
    "vocab = list(set([lintWord(w) for w in words if not w in stopwords.words(\"english\")]))\n",
    "\n",
    "#n eed to remove stopwords again because some of them may have had punctuation \n",
    "# at the end and didnt get caught the first time\n",
    "vocab = [w for w in vocab if not w in stopwords.words(\"english\") and len(w) > 2]\n",
    "\n",
    "#vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3039\n",
      "3039\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(len(set(vocab)))\n",
    "print(\"i\" in vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Algorithm: Aspect Segmentation Algorithm\n",
    "Input: A collection of reviews {푑1, 푑2, . . . , 푑∣퐷∣)}, set of\n",
    "aspect keywords {푇1, 푇2, . . . , 푇푘}, vocabulary V, selection\n",
    "threshold p and iteration step limit I.\n",
    "Output: Reviews split into sentences with aspect assignments.\n",
    "Step 0: Split all reviews into sentences, 푋 =\n",
    "{푥1, 푥2, . . . , 푥푀};\n",
    "Step 1: Match the aspect keywords in each sentence\n",
    "of X and record the matching hits for each aspect i in\n",
    "퐶표푢푛푡(푖);\n",
    "Step 2: Assign the sentence an aspect label by 푎푖 =\n",
    "푎푟푔푚푎푥푖 퐶표푢푛푡(푖). If there is a tie, assign the sentence\n",
    "with multiple aspects.\n",
    "Step 3: Calculate chi^2 measure of each word (in V);\n",
    "Step 4: Rank the words under each aspect with respect\n",
    "to their chi^2value and join the top p words for each aspect\n",
    "into their corresponding aspect keyword list 푇푖;\n",
    "Step 5: If the aspect keyword list is unchanged or iteration\n",
    "exceeds I, go to Step 6, else go to Step 1;\n",
    "Step 6: Output the annotated sentences with aspect\n",
    "assignments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer to split sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business', 'center', 'computer', 'internet'],\n",
      " 'Check in / front desk': ['stuff', 'check', 'help', 'reservation'],\n",
      " 'Cleanliness': ['clean', 'dirty', 'maintain', 'smell'],\n",
      " 'Location': ['location', 'traffic', 'minute', 'restaurant'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed'],\n",
      " 'Service': ['service', 'food', 'breakfast', 'buffet'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business',\n",
      "                      'center',\n",
      "                      'computer',\n",
      "                      'internet',\n",
      "                      'access',\n",
      "                      'wireless',\n",
      "                      'work'],\n",
      " 'Check in / front desk': ['stuff',\n",
      "                           'check',\n",
      "                           'help',\n",
      "                           'reservation',\n",
      "                           'real',\n",
      "                           'set',\n",
      "                           'efficient'],\n",
      " 'Cleanliness': ['clean',\n",
      "                 'dirty',\n",
      "                 'maintain',\n",
      "                 'smell',\n",
      "                 'nice---light--not',\n",
      "                 'definetly',\n",
      "                 'multitude'],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              'central',\n",
      "              'pioneer',\n",
      "              'eat'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed', 'comfortable', 'king', 'booked'],\n",
      " 'Service': ['service',\n",
      "             'food',\n",
      "             'breakfast',\n",
      "             'buffet',\n",
      "             'ate',\n",
      "             'restaurant',\n",
      "             'customer'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth', 'reasonable', 'pricey', 'per']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business',\n",
      "                      'center',\n",
      "                      'computer',\n",
      "                      'internet',\n",
      "                      'access',\n",
      "                      'wireless',\n",
      "                      'work',\n",
      "                      'fitness',\n",
      "                      'ethernet',\n",
      "                      'wired'],\n",
      " 'Check in / front desk': ['stuff',\n",
      "                           'check',\n",
      "                           'help',\n",
      "                           'reservation',\n",
      "                           'real',\n",
      "                           'set',\n",
      "                           'efficient',\n",
      "                           'radius',\n",
      "                           'adviser',\n",
      "                           'printout'],\n",
      " 'Cleanliness': ['clean',\n",
      "                 'dirty',\n",
      "                 'maintain',\n",
      "                 'smell',\n",
      "                 'nice---light--not',\n",
      "                 'definetly',\n",
      "                 'multitude',\n",
      "                 'pocket',\n",
      "                 'strangers',\n",
      "                 'hospitable'],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              'central',\n",
      "              'pioneer',\n",
      "              'eat',\n",
      "              'square',\n",
      "              'ideally',\n",
      "              'planned'],\n",
      " 'Rooms': ['room',\n",
      "           'suite',\n",
      "           'view',\n",
      "           'bed',\n",
      "           'comfortable',\n",
      "           'king',\n",
      "           'booked',\n",
      "           'spacious',\n",
      "           'large',\n",
      "           'couch'],\n",
      " 'Service': ['service',\n",
      "             'food',\n",
      "             'breakfast',\n",
      "             'buffet',\n",
      "             'ate',\n",
      "             'restaurant',\n",
      "             'customer',\n",
      "             'prompt',\n",
      "             'fast',\n",
      "             'order'],\n",
      " 'Value': ['value',\n",
      "           'price',\n",
      "           'quality',\n",
      "           'worth',\n",
      "           'reasonable',\n",
      "           'pricey',\n",
      "           'per',\n",
      "           'full',\n",
      "           'option',\n",
      "           '800']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "done, time taken: 74.48329997062683\n"
     ]
    }
   ],
   "source": [
    "# initial seeds from LARA paper\n",
    "seeds = {\"Value\" : [\"value\", \"price\", \"quality\",\"worth\"],\n",
    "         \"Rooms\" : [\"room\", \"suite\", \"view\", \"bed\"],\n",
    "         \"Location\" : [\"location\", \"traffic\", \"minute\", \"restaurant\"],\n",
    "         \"Cleanliness\" : [\"clean\", \"dirty\", \"maintain\", \"smell\"],\n",
    "         \"Check in / front desk\": [\"stuff\", \"check\", \"help\", \"reservation\"],\n",
    "         \"Service\" : [\"service\", \"food\", \"breakfast\", \"buffet\"],\n",
    "         \"Business service\" : [\"business\", \"center\", \"computer\", \"internet\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def aspectSegmentation(reviews, aspects, vocab=[], threshold=0, iterationLimit=3):\n",
    "    #when we have the top chi-squared rated keywords, how many do we take\n",
    "    keywordsToTake = 3\n",
    "    \n",
    "    #bootstrap iterations\n",
    "    for i in range(0, iterationLimit):\n",
    "        \n",
    "        #print our current aspects\n",
    "        print(\"begin bootstrapping iteration, aspect keywords: \")\n",
    "        pp.pprint(aspects)\n",
    "        print(\"\\n\\n\\n\")\n",
    "        labeledSentences = []\n",
    "        for r in reviews:\n",
    "            #use the pickle tokenizer to split sentences\n",
    "            sentences = tokenizer.tokenize(r)\n",
    "            \n",
    "            for s in sentences:\n",
    "                \n",
    "                theseAspects = collections.defaultdict(int)\n",
    "                maxAspect = (0, \"None\")\n",
    "                \n",
    "                #for each aspect count how many times one of those aspect words appears\n",
    "                for a in aspects:\n",
    "                    for word in aspects[a]:\n",
    "                        if \" \"+word+\" \" in s:\n",
    "                            theseAspects[a] += 1\n",
    "                \n",
    "                #find the max occuring aspect for each sentence, take multiple if ties\n",
    "                for a in theseAspects:\n",
    "                    if theseAspects[a] > maxAspect[0]:\n",
    "                        maxAspect = (theseAspects[a], a)\n",
    "                    if theseAspects[a] == maxAspect[0] and a not in maxAspect:\n",
    "                        #label it with multiple aspects\n",
    "                        maxAspect = maxAspect + (a, )\n",
    "                \n",
    "                #add the sentence with labels\n",
    "                labeledSentences.append((s, maxAspect[1:]))\n",
    "            \n",
    "        \n",
    "        chiSquaredForAspects = collections.defaultdict(list)\n",
    "        #calculate chi squared measure for each word in vocab\n",
    "        \"\"\"c1 is the number of times w occurs in sentences belonging\n",
    "            to aspect a_i, c2 is the number of times w occurs\n",
    "            in sentences not belonging to a_i, c3 is the number of sentences\n",
    "            of aspect a_i that do not contain w, c4 is the number\n",
    "            of sentences that neither belong to aspect a_i, nor contain\n",
    "            word w, and C is the total number of word occurrences\"\"\"\n",
    "        for w in vocab:\n",
    "            for a in aspects:\n",
    "                c = 0\n",
    "                c_1 = 0\n",
    "                c_2 = 0 \n",
    "                c_3 = 0\n",
    "                c_4 = 0\n",
    "\n",
    "                for s in labeledSentences:\n",
    "                    sentenceText = s[0]\n",
    "                    sentenceAspects = s[1]\n",
    "\n",
    "                    if \" \"+w+\" \" in sentenceText and a in sentenceAspects:\n",
    "                        c_1 += 1\n",
    "                    elif \" \"+w+\" \" in sentenceText and a not in sentenceAspects:\n",
    "                        c_2 += 1\n",
    "                    elif a in sentenceAspects and w not in sentenceText:\n",
    "                        c_3 += 1\n",
    "                    else:\n",
    "                        c_4 += 1\n",
    "\n",
    "                numer = ((1.0 * c_1 * c_4 - 1.0 * c_2 * c_3)**2)\n",
    "                denom = (1.0*(c_1 + c_3) * 1.0 * (c_2 + c_4) * 1.0 * (c_1 + c_2) * 1.0 * (c_3 + c_4))\n",
    "                #unreasonable use of 1.0's here to be safe\n",
    "                if denom != 0:\n",
    "                    csq = numer / denom\n",
    "                    chiSquaredForAspects[a].append((w, csq))\n",
    "\n",
    "\n",
    "        #have the chi squared aspects for each word in vocab, add top kewordsToTake for each aspect\n",
    "        for a in chiSquaredForAspects:\n",
    "            #make sure were not taking words we already have\n",
    "            noDupes = [tup for tup in chiSquaredForAspects[a] if tup[0] not in aspects[a]]\n",
    "            chiSquaredForAspects[a] = sorted(noDupes, key=itemgetter(1), reverse=True)[0:keywordsToTake]\n",
    "            for t in chiSquaredForAspects[a]:\n",
    "                if t[0] not in aspects[a] and t[0] != '':\n",
    "                    aspects[a].append(t[0])\n",
    "            \n",
    "            \n",
    "        \n",
    "            #split into sentences\n",
    "        \n",
    "        #loop through again\n",
    "    return labeledSentences\n",
    "    #return labeledSentences\n",
    "\n",
    "start = time.time()\n",
    "sentencesWLabels = aspectSegmentation(data[\"Content\"], seeds, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"done, time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numToShow = 20\n",
    "count = 0\n",
    "for s in sentencesWLabels:\n",
    "    if 'None' not in s[1]:\n",
    "        print(s)\n",
    "        print(\"\\n\")\n",
    "        count += 1\n",
    "    if count > numToShow:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#seeds will have changed, whats differet\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seedInReview(review, seeds):\n",
    "    for s in seeds:\n",
    "        #print(s)\n",
    "        if s in review:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "reviewsWithSeeds = {}\n",
    "for s in seeds:\n",
    "    reviewsWithSeeds[s] = sum(data[\"Content\"].apply(seedInReview, args = [seeds[s]]))\n",
    "reviewsWithSeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       422\n",
       "1      1435\n",
       "2       969\n",
       "3       382\n",
       "4       624\n",
       "5      2890\n",
       "6      2419\n",
       "7      3550\n",
       "8       250\n",
       "9        66\n",
       "10      418\n",
       "11      641\n",
       "12      791\n",
       "13     1372\n",
       "14       80\n",
       "15      882\n",
       "16      881\n",
       "17      395\n",
       "18      697\n",
       "19      968\n",
       "20      353\n",
       "21     1283\n",
       "22      295\n",
       "23      508\n",
       "24       79\n",
       "25     1058\n",
       "26      757\n",
       "27     2432\n",
       "28      293\n",
       "29     2160\n",
       "       ... \n",
       "94     1260\n",
       "95     1251\n",
       "96      617\n",
       "97     1314\n",
       "98      922\n",
       "99      571\n",
       "100     195\n",
       "101     501\n",
       "102     303\n",
       "103    2236\n",
       "104    1849\n",
       "105     511\n",
       "106     300\n",
       "107    1226\n",
       "108     575\n",
       "109     354\n",
       "110    1834\n",
       "111    1569\n",
       "112     707\n",
       "113     238\n",
       "114    1106\n",
       "115     502\n",
       "116    1715\n",
       "117     658\n",
       "118     921\n",
       "119     449\n",
       "120    3375\n",
       "121    1479\n",
       "122     662\n",
       "123     642\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getContentLen(rev):\n",
    "    return len(rev[\"Content\"])\n",
    "\n",
    "data.apply(getContentLen, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasonable', 'worth', 'value', '$217', 'per', '800', 'sign', 'quality', 'full', 'price', 'pricey', 'option', 'accessories'}\n",
      "0 422\n",
      "PST 0\n",
      "0 422\n",
      "PST 0\n",
      "0 1435\n",
      "PST 0\n",
      "0 969\n",
      "PST 0\n",
      "0 382\n",
      "PST 0\n",
      "0 624\n",
      "PST 0\n",
      "0 2890\n",
      "PST 0\n",
      "490 2419\n",
      "PST 490\n",
      "639 3550\n",
      "PST 639\n",
      "0 250\n",
      "PST 0\n"
     ]
    }
   ],
   "source": [
    "aspect = \"Value\"\n",
    "\n",
    "def filterReviewSentencesByWords(rev, words):\n",
    "    #tokenize review into sentences\n",
    "    sentences = tokenizer.tokenize(rev[\"Content\"])\n",
    "    \n",
    "    \n",
    "    newContent = \"\"\n",
    "    for s in sentences:\n",
    "        wordlist = re.sub(\"[^a-zA-Z]\",\" \", s).split()\n",
    "        intersect = set(wordlist).intersection(words)\n",
    "        \n",
    "        if len(intersect) != 0:\n",
    "            newContent += s \n",
    "\n",
    "    \n",
    "    if len(newContent) == 0:\n",
    "        #so no sentences contain the rating? what do we do ehre\n",
    "        pass\n",
    "    rev[\"Content\"] = newContent\n",
    "\n",
    "    return rev\n",
    "\n",
    "def filterReviewsByAspectWords(data, seeds):\n",
    "    #we have our seeds, now let's only keep the sentences which are relevant to that aspect in each review\n",
    "    aspectWords = set(seeds[aspect])\n",
    "    \n",
    "    \n",
    "    data = data.apply(filterReviewSentencesByWords, axis=1, args=(aspectWords,))\n",
    "    return data\n",
    "    \n",
    "data = filterReviewsByAspectWords(data[0:9], seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hilobb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Chianti_girl24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Oct 13, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MauiDiver</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sep 15, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tulane86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>in comparison to the w, i spent about $45 more...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Sep 15, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kstenger</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>our daughter's 9th birthday was 09.13.08 and w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Sep 1, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cantwaitNy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service  Business service          Author  \\\n",
       "0    5.0  Dec 23, 2008       5.0      5.0               NaN     selizabethm   \n",
       "1    4.0  Nov 13, 2008       5.0      5.0               NaN       IndieLady   \n",
       "2    4.0  Nov 11, 2008       3.0      NaN               4.0          Hilobb   \n",
       "3    5.0   Nov 4, 2008       5.0      5.0               5.0  Chianti_girl24   \n",
       "4    NaN  Oct 18, 2008       NaN      NaN               NaN      hothearted   \n",
       "5    3.0  Oct 13, 2008       3.0      2.0               3.0       MauiDiver   \n",
       "6    4.0  Sep 15, 2008       5.0      3.0               5.0        Tulane86   \n",
       "7    5.0  Sep 15, 2008       5.0      5.0               NaN        kstenger   \n",
       "8    5.0   Sep 1, 2008       5.0      4.0               3.0      cantwaitNy   \n",
       "\n",
       "   Check in / front desk  No. Helpful  Cleanliness  \\\n",
       "0                    5.0          NaN          5.0   \n",
       "1                    5.0          NaN          4.0   \n",
       "2                    5.0          NaN          4.0   \n",
       "3                    5.0          NaN          5.0   \n",
       "4                    NaN          2.0          NaN   \n",
       "5                    2.0          1.0          5.0   \n",
       "6                    1.0          1.0          5.0   \n",
       "7                    5.0          4.0          5.0   \n",
       "8                    5.0          NaN          5.0   \n",
       "\n",
       "                                             Content  Value  No. Reader  \\\n",
       "0                                                       4.0         NaN   \n",
       "1                                                       5.0         NaN   \n",
       "2                                                       4.0         NaN   \n",
       "3                                                       5.0         NaN   \n",
       "4                                                       NaN         2.0   \n",
       "5                                                       2.0         2.0   \n",
       "6  in comparison to the w, i spent about $45 more...    2.0         3.0   \n",
       "7  our daughter's 9th birthday was 09.13.08 and w...    5.0         4.0   \n",
       "8                                                       5.0         NaN   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  \n",
       "5      2.0  \n",
       "6      3.0  \n",
       "7      5.0  \n",
       "8      5.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
