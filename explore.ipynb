{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "import pprint as pp\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "\n",
    "\n",
    "#data from http://times.cs.uiuc.edu/~wang296/Data/\n",
    "files = os.listdir('./Review_Texts')\n",
    "#print(os.listdir('./Review_Texts'))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = ['Rooms', 'Date', 'Location', 'Service', 'Business service', 'Author', 'Check in / front desk', 'No. Helpful', 'Cleanliness', 'Content', 'Value', 'No. Reader', 'Overall']\n",
    "data = pd.DataFrame(columns=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFileToData(filename, data):\n",
    "    intColumns = ['No. Reader', 'No. Helpful', 'Cleanliness','Check in / front desk', 'Value', 'Overall', 'Service', 'Business service', 'Rooms', 'Location']\n",
    "    \n",
    "    with open(filename, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "\n",
    "    #print(content)\n",
    "    reviews = content.split(\"\\n\\n\")\n",
    "    \n",
    "    for r in reviews:\n",
    "        #print(r)\n",
    "        thisReview = pd.Series([None]*len(cats), cats)\n",
    "        splt = r.split(\"\\n\")\n",
    "        for s in splt:\n",
    "            for c in cats:\n",
    "                if \"<\"+c+\">\" in s:\n",
    "                    value = s.replace('<'+c+'>', '')\n",
    "                    if c in intColumns:\n",
    "                        value = int(value)\n",
    "                    if value == -1: #we dont want -1 as this is going to mess up averaging, take np.nan\n",
    "                        value = np.nan\n",
    "\n",
    "                    if c == \"Content\":\n",
    "                        value = value.lower()\n",
    "\n",
    "                    thisReview[c] = value\n",
    "        #print(thisReview)\n",
    "        if not thisReview[\"Content\"] == None and len(thisReview[\"Content\"]) > 60:\n",
    "            data = data.append(thisReview, ignore_index=True)\n",
    "    return data\n",
    "        \n",
    "data = addFileToData('./Review_Texts/hotel_100504.dat', data) \n",
    "data = addFileToData('./Review_Texts/hotel_72572.dat', data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Hilobb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chianti_girl24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loved the monaco! staff was amazing, with a sm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service Business service          Author  \\\n",
       "0    5.0  Dec 23, 2008       5.0      5.0              NaN     selizabethm   \n",
       "1    4.0  Nov 13, 2008       5.0      5.0              NaN       IndieLady   \n",
       "2    4.0  Nov 11, 2008       3.0      NaN                4          Hilobb   \n",
       "3    5.0   Nov 4, 2008       5.0      5.0                5  Chianti_girl24   \n",
       "4    NaN  Oct 18, 2008       NaN      NaN              NaN      hothearted   \n",
       "\n",
       "   Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0                    5.0         NaN          5.0   \n",
       "1                    5.0         NaN          4.0   \n",
       "2                    5.0         NaN          4.0   \n",
       "3                    5.0         NaN          5.0   \n",
       "4                    NaN           2          NaN   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  wonderful time- even with the snow! what a gre...    4.0        NaN   \n",
       "1  lovely hotel, unique decor, friendly front des...    5.0        NaN   \n",
       "2  nice hotel, expensive parking we got a good de...    4.0        NaN   \n",
       "3  fabulous hotel location and service are great....    5.0        NaN   \n",
       "4  loved the monaco! staff was amazing, with a sm...    NaN          2   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rooms                    4.208589\n",
       "Location                 4.296875\n",
       "Service                  4.167702\n",
       "Check in / front desk    4.273438\n",
       "Cleanliness              4.518293\n",
       "Value                    3.969136\n",
       "Overall                  4.165829\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean of int columns\n",
    "data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"Content\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating the vocab of all the words\n",
    "\n",
    "def lintWord(w):\n",
    "    regex = re.compile(r'(,|\\(|\\)|!|:|$|\\.)')\n",
    "    w = re.sub(regex, '', w)\n",
    "    return w\n",
    "\n",
    "\n",
    "allWords = \"\"\n",
    "for r in data[\"Content\"]:\n",
    "    #add word to big content string\n",
    "    allWords += r + \" \"\n",
    "    \n",
    "#split the string at spaces, keep only unique\n",
    "words = set(allWords.split(\" \"))\n",
    "\n",
    "\n",
    "vocab = list(set([lintWord(w) for w in words if not w in stopwords.words(\"english\")]))\n",
    "\n",
    "#n eed to remove stopwords again because some of them may have had punctuation \n",
    "# at the end and didnt get caught the first time\n",
    "vocab = [w for w in vocab if not w in stopwords.words(\"english\") and len(w) > 2]\n",
    "\n",
    "#vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3776\n",
      "3776\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(len(set(vocab)))\n",
    "print(\"i\" in vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithm: Aspect Segmentation Algorithm\\nInput: A collection of reviews {푑1, 푑2, . . . , 푑∣퐷∣)}, set of\\naspect keywords {푇1, 푇2, . . . , 푇푘}, vocabulary V, selection\\nthreshold p and iteration step limit I.\\nOutput: Reviews split into sentences with aspect assignments.\\nStep 0: Split all reviews into sentences, 푋 =\\n{푥1, 푥2, . . . , 푥푀};\\nStep 1: Match the aspect keywords in each sentence\\nof X and record the matching hits for each aspect i in\\n퐶표푢푛푡(푖);\\nStep 2: Assign the sentence an aspect label by 푎푖 =\\n푎푟푔푚푎푥푖 퐶표푢푛푡(푖). If there is a tie, assign the sentence\\nwith multiple aspects.\\nStep 3: Calculate chi^2 measure of each word (in V);\\nStep 4: Rank the words under each aspect with respect\\nto their chi^2value and join the top p words for each aspect\\ninto their corresponding aspect keyword list 푇푖;\\nStep 5: If the aspect keyword list is unchanged or iteration\\nexceeds I, go to Step 6, else go to Step 1;\\nStep 6: Output the annotated sentences with aspect\\nassignments.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"Algorithm: Aspect Segmentation Algorithm\n",
    "Input: A collection of reviews {푑1, 푑2, . . . , 푑∣퐷∣)}, set of\n",
    "aspect keywords {푇1, 푇2, . . . , 푇푘}, vocabulary V, selection\n",
    "threshold p and iteration step limit I.\n",
    "Output: Reviews split into sentences with aspect assignments.\n",
    "Step 0: Split all reviews into sentences, 푋 =\n",
    "{푥1, 푥2, . . . , 푥푀};\n",
    "Step 1: Match the aspect keywords in each sentence\n",
    "of X and record the matching hits for each aspect i in\n",
    "퐶표푢푛푡(푖);\n",
    "Step 2: Assign the sentence an aspect label by 푎푖 =\n",
    "푎푟푔푚푎푥푖 퐶표푢푛푡(푖). If there is a tie, assign the sentence\n",
    "with multiple aspects.\n",
    "Step 3: Calculate chi^2 measure of each word (in V);\n",
    "Step 4: Rank the words under each aspect with respect\n",
    "to their chi^2value and join the top p words for each aspect\n",
    "into their corresponding aspect keyword list 푇푖;\n",
    "Step 5: If the aspect keyword list is unchanged or iteration\n",
    "exceeds I, go to Step 6, else go to Step 1;\n",
    "Step 6: Output the annotated sentences with aspect\n",
    "assignments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer to split sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business', 'center', 'computer', 'internet'],\n",
      " 'Check in / front desk': ['stuff', 'check', 'help', 'reservation'],\n",
      " 'Cleanliness': ['clean', 'dirty', 'maintain', 'smell'],\n",
      " 'Location': ['location', 'traffic', 'minute', 'restaurant'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed'],\n",
      " 'Service': ['service', 'food', 'breakfast', 'buffet'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business',\n",
      "                      'center',\n",
      "                      'computer',\n",
      "                      'internet',\n",
      "                      'wireless',\n",
      "                      'access',\n",
      "                      'fitness'],\n",
      " 'Check in / front desk': ['stuff',\n",
      "                           'check',\n",
      "                           'help',\n",
      "                           'reservation',\n",
      "                           'persons',\n",
      "                           'skills',\n",
      "                           'you鈥檒l'],\n",
      " 'Cleanliness': ['clean',\n",
      "                 'dirty',\n",
      "                 'maintain',\n",
      "                 'smell',\n",
      "                 'era',\n",
      "                 'counters',\n",
      "                 'fixtures'],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              'central',\n",
      "              'convenient',\n",
      "              'eat'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed', 'spacious', 'comfortable', 'king'],\n",
      " 'Service': ['service',\n",
      "             'food',\n",
      "             'breakfast',\n",
      "             'buffet',\n",
      "             'continental',\n",
      "             'customer',\n",
      "             'ate'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth', 'cent', 'fully', 'cable']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business',\n",
      "                      'center',\n",
      "                      'computer',\n",
      "                      'internet',\n",
      "                      'wireless',\n",
      "                      'access',\n",
      "                      'fitness',\n",
      "                      'frequent',\n",
      "                      'ethernet',\n",
      "                      'wired'],\n",
      " 'Check in / front desk': ['stuff',\n",
      "                           'check',\n",
      "                           'help',\n",
      "                           'reservation',\n",
      "                           'persons',\n",
      "                           'skills',\n",
      "                           'you鈥檒l',\n",
      "                           'unplugged',\n",
      "                           '-some',\n",
      "                           'holes'],\n",
      " 'Cleanliness': ['clean',\n",
      "                 'dirty',\n",
      "                 'maintain',\n",
      "                 'smell',\n",
      "                 'era',\n",
      "                 'counters',\n",
      "                 'fixtures',\n",
      "                 'usual',\n",
      "                 'pretentious',\n",
      "                 \"1880's\"],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              'central',\n",
      "              'convenient',\n",
      "              'eat',\n",
      "              'great',\n",
      "              'ideally',\n",
      "              'downtown'],\n",
      " 'Rooms': ['room',\n",
      "           'suite',\n",
      "           'view',\n",
      "           'bed',\n",
      "           'spacious',\n",
      "           'comfortable',\n",
      "           'king',\n",
      "           'large',\n",
      "           'size',\n",
      "           'couch'],\n",
      " 'Service': ['service',\n",
      "             'food',\n",
      "             'breakfast',\n",
      "             'buffet',\n",
      "             'continental',\n",
      "             'customer',\n",
      "             'ate',\n",
      "             'restaurant',\n",
      "             'prompt',\n",
      "             'lacking'],\n",
      " 'Value': ['value',\n",
      "           'price',\n",
      "           'quality',\n",
      "           'worth',\n",
      "           'cent',\n",
      "           'fully',\n",
      "           'cable',\n",
      "           '$45',\n",
      "           'retrospect',\n",
      "           'boiled']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "done, time taken: 123.16629219055176\n"
     ]
    }
   ],
   "source": [
    "# initial seeds from LARA paper\n",
    "seeds = {\"Value\" : [\"value\", \"price\", \"quality\",\"worth\"],\n",
    "         \"Rooms\" : [\"room\", \"suite\", \"view\", \"bed\"],\n",
    "         \"Location\" : [\"location\", \"traffic\", \"minute\", \"restaurant\"],\n",
    "         \"Cleanliness\" : [\"clean\", \"dirty\", \"maintain\", \"smell\"],\n",
    "         \"Check in / front desk\": [\"stuff\", \"check\", \"help\", \"reservation\"],\n",
    "         \"Service\" : [\"service\", \"food\", \"breakfast\", \"buffet\"],\n",
    "         \"Business service\" : [\"business\", \"center\", \"computer\", \"internet\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def aspectSegmentation(reviews, aspects, vocab=[], threshold=0, iterationLimit=3):\n",
    "    #when we have the top chi-squared rated keywords, how many do we take\n",
    "    keywordsToTake = 3\n",
    "    \n",
    "    #bootstrap iterations\n",
    "    for i in range(0, iterationLimit):\n",
    "        \n",
    "        #print our current aspects\n",
    "        print(\"begin bootstrapping iteration, aspect keywords: \")\n",
    "        pp.pprint(aspects)\n",
    "        print(\"\\n\\n\\n\")\n",
    "        labeledSentences = []\n",
    "        for r in reviews:\n",
    "            #use the pickle tokenizer to split sentences\n",
    "            sentences = tokenizer.tokenize(r)\n",
    "            \n",
    "            for s in sentences:\n",
    "                \n",
    "                theseAspects = collections.defaultdict(int)\n",
    "                maxAspect = (0, \"None\")\n",
    "                \n",
    "                #for each aspect count how many times one of those aspect words appears\n",
    "                for a in aspects:\n",
    "                    for word in aspects[a]:\n",
    "                        if \" \"+word+\" \" in s:\n",
    "                            theseAspects[a] += 1\n",
    "                \n",
    "                #find the max occuring aspect for each sentence, take multiple if ties\n",
    "                for a in theseAspects:\n",
    "                    if theseAspects[a] > maxAspect[0]:\n",
    "                        maxAspect = (theseAspects[a], a)\n",
    "                    if theseAspects[a] == maxAspect[0] and a not in maxAspect:\n",
    "                        #label it with multiple aspects\n",
    "                        maxAspect = maxAspect + (a, )\n",
    "                \n",
    "                #add the sentence with labels\n",
    "                labeledSentences.append((s, maxAspect[1:]))\n",
    "            \n",
    "        \n",
    "        chiSquaredForAspects = collections.defaultdict(list)\n",
    "        #calculate chi squared measure for each word in vocab\n",
    "        \"\"\"c1 is the number of times w occurs in sentences belonging\n",
    "            to aspect a_i, c2 is the number of times w occurs\n",
    "            in sentences not belonging to a_i, c3 is the number of sentences\n",
    "            of aspect a_i that do not contain w, c4 is the number\n",
    "            of sentences that neither belong to aspect a_i, nor contain\n",
    "            word w, and C is the total number of word occurrences\"\"\"\n",
    "        for w in vocab:\n",
    "            for a in aspects:\n",
    "                c = 0\n",
    "                c_1 = 0\n",
    "                c_2 = 0 \n",
    "                c_3 = 0\n",
    "                c_4 = 0\n",
    "\n",
    "                for s in labeledSentences:\n",
    "                    sentenceText = s[0]\n",
    "                    sentenceAspects = s[1]\n",
    "\n",
    "                    if \" \"+w+\" \" in sentenceText and a in sentenceAspects:\n",
    "                        c_1 += 1\n",
    "                    elif \" \"+w+\" \" in sentenceText and a not in sentenceAspects:\n",
    "                        c_2 += 1\n",
    "                    elif a in sentenceAspects and w not in sentenceText:\n",
    "                        c_3 += 1\n",
    "                    else:\n",
    "                        c_4 += 1\n",
    "\n",
    "                numer = ((1.0 * c_1 * c_4 - 1.0 * c_2 * c_3)**2)\n",
    "                denom = (1.0*(c_1 + c_3) * 1.0 * (c_2 + c_4) * 1.0 * (c_1 + c_2) * 1.0 * (c_3 + c_4))\n",
    "                #unreasonable use of 1.0's here to be safe\n",
    "                if denom != 0:\n",
    "                    csq = numer / denom\n",
    "                    chiSquaredForAspects[a].append((w, csq))\n",
    "\n",
    "\n",
    "        #have the chi squared aspects for each word in vocab, add top kewordsToTake for each aspect\n",
    "        for a in chiSquaredForAspects:\n",
    "            #make sure were not taking words we already have\n",
    "            noDupes = [tup for tup in chiSquaredForAspects[a] if tup[0] not in aspects[a]]\n",
    "            chiSquaredForAspects[a] = sorted(noDupes, key=itemgetter(1), reverse=True)[0:keywordsToTake]\n",
    "            for t in chiSquaredForAspects[a]:\n",
    "                if t[0] not in aspects[a] and t[0] != '':\n",
    "                    aspects[a].append(t[0])\n",
    "            \n",
    "            \n",
    "        \n",
    "            #split into sentences\n",
    "        \n",
    "        #loop through again\n",
    "    return labeledSentences\n",
    "    #return labeledSentences\n",
    "\n",
    "start = time.time()\n",
    "sentencesWLabels = aspectSegmentation(data[\"Content\"], seeds, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"done, time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('what a great experience!', ('Location',))\n",
      "\n",
      "\n",
      "('from the goldfish in the room (which my daughter loved) to the fact that the valet parking staff who put on my chains on for me it was fabulous.', ('Rooms',))\n",
      "\n",
      "\n",
      "(\"oh, and about the parking: the charge is about what you would pay at any garage or lot- and i bet they wouldn't help you out in the snow! \", ('Check in / front desk',))\n",
      "\n",
      "\n",
      "(\"lovely hotel, unique decor, friendly front desk staff, central location it's only recently that i've started staying at boutique hotels, so i'm definitely not an expert on the subtleties that these types of establishments provide.\", ('Location',))\n",
      "\n",
      "\n",
      "('our room provided a nice view and had this modern, romantic, shabby-chic feel to it, for lack of a better description.', ('Rooms',))\n",
      "\n",
      "\n",
      "('sazerac restaurant served us delicious breakfast in a really great setting.', ('Service', 'Location'))\n",
      "\n",
      "\n",
      "('the location was ideal!', ('Location',))\n",
      "\n",
      "\n",
      "('we were a little disappointed by the (non-existent) view from the room, but the room itself was clean and a nice size.', ('Rooms',))\n",
      "\n",
      "\n",
      "('the bed was comfortable, but i woke up with a stiff neck from the high pillows.', ('Rooms',))\n",
      "\n",
      "\n",
      "('it was not as soundproof as we like...we heard music from the next room at night, and in the morning there were loud bangs from doors opening and closing, and we could hear people talking in the hallway.', ('Rooms',))\n",
      "\n",
      "\n",
      "('fabulous hotel location and service are great.', ('Service', 'Location'))\n",
      "\n",
      "\n",
      "('the valet was a doll, the front desk got me to my room quickly and everytime i passed through the lobby, the staff had huge smiles on their faces.', ('Rooms',))\n",
      "\n",
      "\n",
      "('rooms were incredibly comfortable and clean.', ('Rooms',))\n",
      "\n",
      "\n",
      "('ginger snap cocktails in the restaurant made night.', ('Service', 'Location'))\n",
      "\n",
      "\n",
      "('well to start off i booked a suite and paid extra and then found that their website description is not what you get.', ('Rooms',))\n",
      "\n",
      "\n",
      "('a suite has more than a bedroom and a bathroom (standard hotel room).', ('Rooms',))\n",
      "\n",
      "\n",
      "('when i took my printed reservation down to the front desk and showed them that it said things like two tv, a couch, ect, the desk clerk told me oh, they mixed two suites into the same description on the kimpton website - sorry about that how about a free breakfast.', ('Check in / front desk',))\n",
      "\n",
      "\n",
      "('i send the kimpton preferred guest website an email asking about the failure to provide a suite as advertised on their website (my reservation description) (also furnished a hard copy of the reservation printout (from their website) to the front desk manager on duty) and did not get any reply or solution.', ('Check in / front desk', 'Rooms'))\n",
      "\n",
      "\n",
      "('i asked the front desk if their was any good breakfast spots in the neighborhood hood and was told, no only the hotels.', ('Service',))\n",
      "\n",
      "\n",
      "('gee i found one of the best breakfast spots in seattle 1/2 a block away, how convenient that the hotel does not know they exist.', ('Service', 'Location'))\n",
      "\n",
      "\n",
      "('we arrived late the first night (11 pm) and had to go inside and run down the bellman who busy chating on his cell phone to get any help with our bags.prior to my arrival i had emailed the hotel to inform them that it was my 20th anniversary as my other half is really picky so i wanted to make sure everything was good to go.', ('Check in / front desk',))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numToShow = 20\n",
    "count = 0\n",
    "for s in sentencesWLabels:\n",
    "    if 'None' not in s[1]:\n",
    "        print(s)\n",
    "        print(\"\\n\")\n",
    "        count += 1\n",
    "    if count > numToShow:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#seeds will have changed, whats differet\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seedInReview(review, seeds):\n",
    "    for s in seeds:\n",
    "        #print(s)\n",
    "        if s in review:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "reviewsWithSeeds = {}\n",
    "for s in seeds:\n",
    "    reviewsWithSeeds[s] = sum(data[\"Content\"].apply(seedInReview, args = [seeds[s]]))\n",
    "reviewsWithSeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from gensim.models import word2vec\n",
    "# print(\"training\")\n",
    "# model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
