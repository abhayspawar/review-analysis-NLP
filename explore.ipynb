{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "import pprint as pp\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import time\n",
    "import proj_base\n",
    "#data from http://times.cs.uiuc.edu/~wang296/Data/\n",
    "files = os.listdir('./Review_Texts')\n",
    "#print(os.listdir('./Review_Texts'))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proj_base.getStandardData(numFiles=3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008\\r</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Hilobb\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chianti_girl24\\r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008\\r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted\\r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loved the monaco! staff was amazing, with a sm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms            Date  Location  Service Business service  \\\n",
       "0    5.0  Dec 23, 2008\\r       5.0      5.0              NaN   \n",
       "1    4.0  Nov 13, 2008\\r       5.0      5.0              NaN   \n",
       "2    4.0  Nov 11, 2008\\r       3.0      NaN                4   \n",
       "3    5.0   Nov 4, 2008\\r       5.0      5.0                5   \n",
       "4    NaN  Oct 18, 2008\\r       NaN      NaN              NaN   \n",
       "\n",
       "             Author  Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0     selizabethm\\r                    5.0         NaN          5.0   \n",
       "1       IndieLady\\r                    5.0         NaN          4.0   \n",
       "2          Hilobb\\r                    5.0         NaN          4.0   \n",
       "3  Chianti_girl24\\r                    5.0         NaN          5.0   \n",
       "4      hothearted\\r                    NaN           2          NaN   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  wonderful time- even with the snow! what a gre...    4.0        NaN   \n",
       "1  lovely hotel, unique decor, friendly front des...    5.0        NaN   \n",
       "2  nice hotel, expensive parking we got a good de...    4.0        NaN   \n",
       "3  fabulous hotel location and service are great....    5.0        NaN   \n",
       "4  loved the monaco! staff was amazing, with a sm...    NaN          2   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating the vocab of all the words\n",
    "\n",
    "def lintWord(w):\n",
    "    regex = re.compile(r'(,|\\(|\\)|!|:|$|\\.)')\n",
    "    w = re.sub(regex, '', w)\n",
    "    return w\n",
    "\n",
    "\n",
    "allWords = \"\"\n",
    "for r in data[\"Content\"]:\n",
    "    #add word to big content string\n",
    "    allWords += r + \" \"\n",
    "    \n",
    "#split the string at spaces, keep only unique\n",
    "words = set(allWords.split(\" \"))\n",
    "\n",
    "\n",
    "vocab = list(set([lintWord(w) for w in words if not w in stopwords.words(\"english\")]))\n",
    "\n",
    "#n eed to remove stopwords again because some of them may have had punctuation \n",
    "# at the end and didnt get caught the first time\n",
    "vocab = [w for w in vocab if not w in stopwords.words(\"english\") and len(w) > 2]\n",
    "\n",
    "#vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithm: Aspect Segmentation Algorithm\\nInput: A collection of reviews {\\xed\\x91\\x911, \\xed\\x91\\x912, . . . , \\xed\\x91\\x91\\xe2\\x88\\xa3\\xed\\x90\\xb7\\xe2\\x88\\xa3)}, set of\\naspect keywords {\\xed\\x91\\x871, \\xed\\x91\\x872, . . . , \\xed\\x91\\x87\\xed\\x91\\x98}, vocabulary V, selection\\nthreshold p and iteration step limit I.\\nOutput: Reviews split into sentences with aspect assignments.\\nStep 0: Split all reviews into sentences, \\xed\\x91\\x8b =\\n{\\xed\\x91\\xa51, \\xed\\x91\\xa52, . . . , \\xed\\x91\\xa5\\xed\\x91\\x80};\\nStep 1: Match the aspect keywords in each sentence\\nof X and record the matching hits for each aspect i in\\n\\xed\\x90\\xb6\\xed\\x91\\x9c\\xed\\x91\\xa2\\xed\\x91\\x9b\\xed\\x91\\xa1(\\xed\\x91\\x96);\\nStep 2: Assign the sentence an aspect label by \\xed\\x91\\x8e\\xed\\x91\\x96 =\\n\\xed\\x91\\x8e\\xed\\x91\\x9f\\xed\\x91\\x94\\xed\\x91\\x9a\\xed\\x91\\x8e\\xed\\x91\\xa5\\xed\\x91\\x96 \\xed\\x90\\xb6\\xed\\x91\\x9c\\xed\\x91\\xa2\\xed\\x91\\x9b\\xed\\x91\\xa1(\\xed\\x91\\x96). If there is a tie, assign the sentence\\nwith multiple aspects.\\nStep 3: Calculate chi^2 measure of each word (in V);\\nStep 4: Rank the words under each aspect with respect\\nto their chi^2value and join the top p words for each aspect\\ninto their corresponding aspect keyword list \\xed\\x91\\x87\\xed\\x91\\x96;\\nStep 5: If the aspect keyword list is unchanged or iteration\\nexceeds I, go to Step 6, else go to Step 1;\\nStep 6: Output the annotated sentences with aspect\\nassignments.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"Algorithm: Aspect Segmentation Algorithm\n",
    "Input: A collection of reviews {푑1, 푑2, . . . , 푑∣퐷∣)}, set of\n",
    "aspect keywords {푇1, 푇2, . . . , 푇푘}, vocabulary V, selection\n",
    "threshold p and iteration step limit I.\n",
    "Output: Reviews split into sentences with aspect assignments.\n",
    "Step 0: Split all reviews into sentences, 푋 =\n",
    "{푥1, 푥2, . . . , 푥푀};\n",
    "Step 1: Match the aspect keywords in each sentence\n",
    "of X and record the matching hits for each aspect i in\n",
    "퐶표푢푛푡(푖);\n",
    "Step 2: Assign the sentence an aspect label by 푎푖 =\n",
    "푎푟푔푚푎푥푖 퐶표푢푛푡(푖). If there is a tie, assign the sentence\n",
    "with multiple aspects.\n",
    "Step 3: Calculate chi^2 measure of each word (in V);\n",
    "Step 4: Rank the words under each aspect with respect\n",
    "to their chi^2value and join the top p words for each aspect\n",
    "into their corresponding aspect keyword list 푇푖;\n",
    "Step 5: If the aspect keyword list is unchanged or iteration\n",
    "exceeds I, go to Step 6, else go to Step 1;\n",
    "Step 6: Output the annotated sentences with aspect\n",
    "assignments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternate method to get keywords. LARA method based on Chi-square is basically same, but much better\n",
    "def aspectSegmentationBayes(reviews, seeds, freq_threshold = .5, prob_threshold = 0.2, words_per_iter = 4, iters = 3):\n",
    "\n",
    "    #break down reviews into sentences and break down each sentence into words using tokenizer and remove stopwords\n",
    "    # returns list where each item is the list of words in that sentence\n",
    "    sentence_words = []\n",
    "    for review in reviews:\n",
    "        review = review.decode('utf-8')\n",
    "        sentences = nltk.tokenize.sent_tokenize(review)\n",
    "        for sentence in sentences:\n",
    "            sentence_words.append([x.lower() for x in nltk.tokenize.word_tokenize(sentence) if x not in stopwords.words('english') and len(x) > 2])    \n",
    "    \n",
    "\n",
    "    # find Probability(sentence(S) has aspect(A) GIVEN S has word(W)) = count(S that have A and have W) / count(S that have W)\n",
    "\n",
    "    for i in range(iters):\n",
    "        \n",
    "        sents_with_word_asp = {}\n",
    "        sents_with_word = {}\n",
    "        sents_with_aspect = {}\n",
    "        prob_asp_given_word = {}\n",
    "\n",
    "        # calculates counts of (S that have W) and (S that have A and W)\n",
    "        for sentence in sentence_words:\n",
    "            for word in sentence:\n",
    "                sents_with_word[word] = sents_with_word.get(word,0) + 1\n",
    "                for aspect, aspect_words in seeds.items():\n",
    "                    for aspect_word in aspect_words:\n",
    "                        if aspect_word in sentence:\n",
    "                            sents_with_word_asp[(word,aspect)] = sents_with_word_asp.get((word, aspect), 0) + 1\n",
    "                            sents_with_aspect[aspect] = sents_with_aspect.get(aspect,0) + 1\n",
    "                            break\n",
    "\n",
    "        for (word, aspect), count in sents_with_word_asp.items():\n",
    "            #susceptible to low frequencies. hence freq_threshold\n",
    "            #freq_threshold ensures that count(S with  W) is atleast x% of count(S)\n",
    "            if sents_with_word[word] > (freq_threshold/100.0)*len(sentence_words):\n",
    "                prob_asp_given_word[(word,aspect)] = count/float(sents_with_word[word])\n",
    "\n",
    "        prob_asp_given_word_sorted = sorted(prob_asp_given_word.items(), key=itemgetter(1),reverse=True)\n",
    "        \n",
    "        for aspect, word_list in seeds.items():\n",
    "            count = 0\n",
    "            for item in prob_asp_given_word_sorted:\n",
    "                #item is of the form ((word,aspect),probability)\n",
    "                if item[0][1] == aspect:\n",
    "                    if item[0][0] not in word_list:\n",
    "                        if count <= words_per_iter:\n",
    "                            if item[1] >= prob_threshold:\n",
    "                                seeds[aspect].append(item[0][0])\n",
    "                                count += 1\n",
    "                            else:\n",
    "                                #because sorted, the others can't have higher probability\n",
    "                                break\n",
    "                        else:\n",
    "                            # because limiit of words per aspect in this iteration has been reached\n",
    "                            break\n",
    "\n",
    "    return seeds\n",
    "start = time.time()\n",
    "#sentencesWLabels = aspectSegmentation(data[\"Content\"], seeds, vocab)\n",
    "end = time.time()\n",
    "sds = aspectSegmentationBayes(data[\"Content\"], seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business service': ['business',\n",
       "  'center',\n",
       "  'computer',\n",
       "  'internet',\n",
       "  u'access',\n",
       "  u'work',\n",
       "  u'free',\n",
       "  u'used',\n",
       "  u'etc',\n",
       "  u'shuttle',\n",
       "  u'travel',\n",
       "  u'centre',\n",
       "  u'worked',\n",
       "  u'complimentary',\n",
       "  u'hour',\n",
       "  u'blocks',\n",
       "  u'wine',\n",
       "  u'within',\n",
       "  u'per'],\n",
       " 'Check in / front desk': ['stuff',\n",
       "  'check',\n",
       "  'help',\n",
       "  'reservation',\n",
       "  u'hot',\n",
       "  u'website',\n",
       "  u'early',\n",
       "  u'said',\n",
       "  u'clerk',\n",
       "  u'check-in',\n",
       "  u'anything',\n",
       "  u'arrived',\n",
       "  u'desk',\n",
       "  u'checked',\n",
       "  u'front',\n",
       "  u'late',\n",
       "  u'told',\n",
       "  u'rude',\n",
       "  u'different'],\n",
       " 'Cleanliness': ['clean',\n",
       "  'dirty',\n",
       "  'maintain',\n",
       "  'smell',\n",
       "  u'expected',\n",
       "  u'bathroom',\n",
       "  u'nicely',\n",
       "  u'comfortable',\n",
       "  u'quiet',\n",
       "  u'spacious',\n",
       "  u'decorated',\n",
       "  u'plenty',\n",
       "  u'pillows',\n",
       "  u'bed',\n",
       "  u'sheets',\n",
       "  u'king',\n",
       "  u'size',\n",
       "  u'beds',\n",
       "  u'tub'],\n",
       " 'Location': ['location',\n",
       "  'traffic',\n",
       "  'minute',\n",
       "  'restaurant',\n",
       "  u'bar',\n",
       "  u'convenient',\n",
       "  u'perfect',\n",
       "  u'excellent',\n",
       "  u'fabulous',\n",
       "  u'restaurants',\n",
       "  u'although',\n",
       "  u'good',\n",
       "  u'great',\n",
       "  u'grocery',\n",
       "  u'value',\n",
       "  u'breakfast',\n",
       "  u'distance',\n",
       "  u'food',\n",
       "  u'walking'],\n",
       " 'Rooms': ['room',\n",
       "  'suite',\n",
       "  'view',\n",
       "  'bed',\n",
       "  u'spacious',\n",
       "  u'king',\n",
       "  u'size',\n",
       "  u'window',\n",
       "  u'requested',\n",
       "  u'space',\n",
       "  u'needle',\n",
       "  u'floor',\n",
       "  u'request',\n",
       "  u'standard',\n",
       "  u'higher',\n",
       "  u'upon',\n",
       "  u'corner',\n",
       "  u'comfortable',\n",
       "  u'huge'],\n",
       " 'Service': ['service',\n",
       "  'food',\n",
       "  'breakfast',\n",
       "  'buffet',\n",
       "  u'included',\n",
       "  u'restaurant',\n",
       "  u'dinner',\n",
       "  u'excellent',\n",
       "  u'hot',\n",
       "  u'eat',\n",
       "  u'tub',\n",
       "  u'bar',\n",
       "  u'reservations',\n",
       "  u'concierge',\n",
       "  u'fabulous',\n",
       "  u'although',\n",
       "  u'always',\n",
       "  u'shower',\n",
       "  u'housekeeping'],\n",
       " 'Value': ['value',\n",
       "  'price',\n",
       "  'quality',\n",
       "  'worth',\n",
       "  u'money',\n",
       "  u'expensive',\n",
       "  u'care',\n",
       "  u'per',\n",
       "  u'looked',\n",
       "  u'rates',\n",
       "  u'pay',\n",
       "  u'extra',\n",
       "  u'weekend',\n",
       "  u'thought',\n",
       "  u'included',\n",
       "  u'years',\n",
       "  u'especially',\n",
       "  u'parking',\n",
       "  u'website']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeds will have changed, whats differet\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seedInReview(review, seeds):\n",
    "    for s in seeds:\n",
    "        #print(s)\n",
    "        if s in review:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "reviewsWithSeeds = {}\n",
    "for s in seeds:\n",
    "    reviewsWithSeeds[s] = sum(data[\"Content\"].apply(seedInReview, args = [seeds[s]]))\n",
    "reviewsWithSeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getContentLen(rev):\n",
    "    return len(rev[\"Content\"])\n",
    "\n",
    "data.apply(getContentLen, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = proj_base.getStandardData(numFiles=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aspect = \"Value\"\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#okenizer = RegexpTokenizer(r'\\w+')\n",
    "def filterReviewSentencesByWords(rev, words):\n",
    "    #tokenize review into sentences\n",
    "    sentences = tokenizer.tokenize(rev[\"Content\"])\n",
    "    \n",
    "    #print(sentences)\n",
    "    aspSentences = []\n",
    "    for s in sentences:\n",
    "        wordlist = re.sub(\"[^a-zA-Z]\",\" \", s).split()\n",
    "        intersect = set(wordlist).intersection(words)\n",
    "        #print(s)\n",
    "        if len(intersect) != 0:\n",
    "            aspSentences.append(s)\n",
    "\n",
    "    #print(aspSentences)\n",
    "    if len(aspSentences) == 0:\n",
    "        #so no sentences contain the rating? what do we do ehre\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    rev[\"aspectSentences\"] = aspSentences\n",
    "\n",
    "    return rev\n",
    "\n",
    "def getAspectSentencesForReview(data, seedWords):\n",
    "    #we have our seeds, now let's only keep the sentences which are relevant to that aspect in each review \n",
    "    \n",
    "    data = data.apply(filterReviewSentencesByWords, axis=1, args=(seedWords,))\n",
    "    return data\n",
    "\n",
    "def getTrainingData(data):\n",
    "    includeColumns = [\"aspectRating\", \"aspectSentences\", \"Content\", \"Overall\", ]\n",
    "    data = getAspectSentencesForReview(data, seeds[aspect])\n",
    "    data[\"aspectRating\"] = data[aspect]\n",
    "    return data[(pd.notnull(data[aspect])) & (data[\"aspectSentences\"].apply(len) > 0)][includeColumns]\n",
    "    \n",
    "data = getAspectSentencesForReview(data, seeds[aspect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 14)\n",
      "((302, 14), (147, 4))\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "trainingData = getTrainingData(data)\n",
    "print(data.shape, trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectRating</th>\n",
       "      <th>aspectSentences</th>\n",
       "      <th>Content</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[from the goldfish in the room (which my daugh...</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[nice hotel, expensive parking we got a good d...</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[valet parking is the only way to go.]</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[well to start off i booked a suite and paid e...</td>\n",
       "      <td>ok, but nothing special for the $$ they charge...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[didn't provide much guidance on special reque...</td>\n",
       "      <td>nice rooms but not a 4* experience the hotel m...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aspectRating                                    aspectSentences  \\\n",
       "0           4.0  [from the goldfish in the room (which my daugh...   \n",
       "2           4.0  [nice hotel, expensive parking we got a good d...   \n",
       "3           5.0             [valet parking is the only way to go.]   \n",
       "5           2.0  [well to start off i booked a suite and paid e...   \n",
       "6           2.0  [didn't provide much guidance on special reque...   \n",
       "\n",
       "                                             Content  Overall  \n",
       "0  wonderful time- even with the snow! what a gre...      5.0  \n",
       "2  nice hotel, expensive parking we got a good de...      4.0  \n",
       "3  fabulous hotel location and service are great....      5.0  \n",
       "5  ok, but nothing special for the $$ they charge...      2.0  \n",
       "6  nice rooms but not a 4* experience the hotel m...      3.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[(pd.notnull(data[aspect])) & (data[\"aspectSentences\"].apply(len) > 0)]\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2       True\n",
       "3       True\n",
       "4      False\n",
       "5       True\n",
       "6       True\n",
       "7       True\n",
       "8      False\n",
       "9      False\n",
       "10      True\n",
       "11      True\n",
       "12      True\n",
       "13      True\n",
       "14     False\n",
       "15      True\n",
       "16      True\n",
       "17      True\n",
       "18     False\n",
       "19      True\n",
       "20     False\n",
       "21      True\n",
       "22      True\n",
       "23     False\n",
       "24     False\n",
       "25      True\n",
       "26     False\n",
       "27      True\n",
       "28     False\n",
       "29     False\n",
       "       ...  \n",
       "272    False\n",
       "273     True\n",
       "274    False\n",
       "275    False\n",
       "276    False\n",
       "277     True\n",
       "278     True\n",
       "279     True\n",
       "280    False\n",
       "281    False\n",
       "282     True\n",
       "283    False\n",
       "284     True\n",
       "285     True\n",
       "286    False\n",
       "287    False\n",
       "288    False\n",
       "289     True\n",
       "290     True\n",
       "291    False\n",
       "292    False\n",
       "293     True\n",
       "294     True\n",
       "295     True\n",
       "296    False\n",
       "297    False\n",
       "298    False\n",
       "299    False\n",
       "300    False\n",
       "301    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.notnull(data[aspect])) & (data[\"aspectSentences\"].apply(len) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 14)\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "#data[\"aspectSentences\"].apply(len)\n",
    "print(data.shape)\n",
    "print(len(data[(pd.notnull(data[aspect])) & (data[\"aspectSentences\"].apply(len) > 0)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"in comparison to the w, i spent about $45 more per night but had a larger (square footage) room with a great soaking tub (with whirlpool jets) and a nice shower.before my stay, i had the hotel arrange a car service, the price $53 with tip was reasonable and the driver was waiting for me on arrival.checkin was easy but the downside was that with a room that was picked for its 2 person jacuzi tub, i found no bath accessories (salts, bubble bath etc...) and didn't get any during the stay.\"]\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[6][\"aspectSentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
