{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "import pprint as pp\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import time\n",
    "\n",
    "\n",
    "#data from http://times.cs.uiuc.edu/~wang296/Data/\n",
    "files = os.listdir('./Review_Texts')\n",
    "#print(os.listdir('./Review_Texts'))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = ['Rooms', 'Date', 'Location', 'Service', 'Business service', 'Author', 'Check in / front desk', 'No. Helpful', 'Cleanliness', 'Content', 'Value', 'No. Reader', 'Overall']\n",
    "data = pd.DataFrame(columns=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFileToData(filename, data):\n",
    "    intColumns = ['No. Reader', 'No. Helpful', 'Cleanliness','Check in / front desk', 'Value', 'Overall', 'Service', 'Business service', 'Rooms', 'Location']\n",
    "    characterThreshold = 60\n",
    "    with open(filename, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        \n",
    "    reviews = content.split(\"\\n\\n\")\n",
    "    for r in reviews:\n",
    "        thisReview = pd.Series([None]*len(cats), cats)\n",
    "        splt = r.split(\"\\n\")\n",
    "        for s in splt:\n",
    "            for c in cats:\n",
    "                if \"<\"+c+\">\" in s:\n",
    "                    value = s.replace('<'+c+'>', '')\n",
    "                    if c in intColumns:\n",
    "                        value = int(value)\n",
    "                    if value == -1: #we dont want -1 as this is going to mess up averaging, take np.nan\n",
    "                        value = np.nan\n",
    "\n",
    "                    if c == \"Content\":\n",
    "                        value = value.lower()\n",
    "\n",
    "                    thisReview[c] = value\n",
    "                    \n",
    "        if not thisReview[\"Content\"] == None and len(thisReview[\"Content\"]) > characterThreshold:\n",
    "            #only add if theres content and its long enough\n",
    "            data = data.append(thisReview, ignore_index=True)\n",
    "    return data\n",
    "        \n",
    "data = addFileToData('./Review_Texts/hotel_100504.dat', data) \n",
    "data = addFileToData('./Review_Texts/hotel_72572.dat', data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dec 23, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>selizabethm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful time- even with the snow! what a gre...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 13, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IndieLady</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>lovely hotel, unique decor, friendly front des...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 11, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Hilobb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nice hotel, expensive parking we got a good de...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 4, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Chianti_girl24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fabulous hotel location and service are great....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 18, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hothearted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loved the monaco! staff was amazing, with a sm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service Business service          Author  \\\n",
       "0    5.0  Dec 23, 2008       5.0      5.0              NaN     selizabethm   \n",
       "1    4.0  Nov 13, 2008       5.0      5.0              NaN       IndieLady   \n",
       "2    4.0  Nov 11, 2008       3.0      NaN                4          Hilobb   \n",
       "3    5.0   Nov 4, 2008       5.0      5.0                5  Chianti_girl24   \n",
       "4    NaN  Oct 18, 2008       NaN      NaN              NaN      hothearted   \n",
       "\n",
       "   Check in / front desk No. Helpful  Cleanliness  \\\n",
       "0                    5.0         NaN          5.0   \n",
       "1                    5.0         NaN          4.0   \n",
       "2                    5.0         NaN          4.0   \n",
       "3                    5.0         NaN          5.0   \n",
       "4                    NaN           2          NaN   \n",
       "\n",
       "                                             Content  Value No. Reader  \\\n",
       "0  wonderful time- even with the snow! what a gre...    4.0        NaN   \n",
       "1  lovely hotel, unique decor, friendly front des...    5.0        NaN   \n",
       "2  nice hotel, expensive parking we got a good de...    4.0        NaN   \n",
       "3  fabulous hotel location and service are great....    5.0        NaN   \n",
       "4  loved the monaco! staff was amazing, with a sm...    NaN          2   \n",
       "\n",
       "   Overall  \n",
       "0      5.0  \n",
       "1      4.0  \n",
       "2      4.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinayak11\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:18: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "C:\\Users\\Vinayak11\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:22: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "#creating the vocab of all the words\n",
    "\n",
    "def lintWord(w):\n",
    "    regex = re.compile(r'(,|\\(|\\)|!|:|$|\\.)')\n",
    "    w = re.sub(regex, '', w)\n",
    "    return w\n",
    "\n",
    "\n",
    "allWords = \"\"\n",
    "for r in data[\"Content\"]:\n",
    "    #add word to big content string\n",
    "    allWords += r + \" \"\n",
    "    \n",
    "#split the string at spaces, keep only unique\n",
    "words = set(allWords.split(\" \"))\n",
    "\n",
    "\n",
    "vocab = list(set([lintWord(w) for w in words if not w in stopwords.words(\"english\")]))\n",
    "\n",
    "#n eed to remove stopwords again because some of them may have had punctuation \n",
    "# at the end and didnt get caught the first time\n",
    "vocab = [w for w in vocab if not w in stopwords.words(\"english\") and len(w) > 2]\n",
    "\n",
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer to split sentences\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "tokenizer2 = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#Stemmer defined for stemming words\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "#                                    LDA IMPLEMENTATION\n",
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business', 'center', 'computer', 'internet'],\n",
      " 'Check in / front desk': ['stuff', 'check', 'help', 'reservation'],\n",
      " 'Cleanliness': ['clean', 'dirty', 'maintain', 'smell'],\n",
      " 'Location': ['location', 'traffic', 'minute', 'restaurant'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed'],\n",
      " 'Service': ['service', 'food', 'breakfast', 'buffet'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Service:\n",
      "[(0, u'0.041*service + 0.021*hotel + 0.019*room + 0.018*breakfast + 0.012*great')]\n",
      "['service', 'food', 'breakfast', 'buffet', u'hotel', u'room']\n",
      "Business service:\n",
      "[(0, u'0.021*business + 0.020*hotel + 0.014*internet + 0.008*room + 0.008*wireless')]\n",
      "['business', 'center', 'computer', 'internet', u'hotel']\n",
      "Cleanliness:\n",
      "[(0, u'0.046*clean + 0.023*room + 0.021*hotel + 0.014*rooms + 0.012*staff')]\n",
      "['clean', 'dirty', 'maintain', 'smell', u'room', u'hotel']\n",
      "Check in / front desk:\n",
      "[(0, u'0.019*check + 0.012*help + 0.010*desk + 0.010*reservation + 0.009*hotel')]\n",
      "['stuff', 'check', 'help', 'reservation', u'desk']\n",
      "Value:\n",
      "[(0, u'0.024*hotel + 0.018*price + 0.016*worth + 0.016*quality + 0.014*great')]\n",
      "['value', 'price', 'quality', 'worth', u'hotel']\n",
      "Rooms:\n",
      "[(0, u'0.060*room + 0.011*hotel + 0.008*bed + 0.008*suite + 0.008*service')]\n",
      "['room', 'suite', 'view', 'bed', u'hotel']\n",
      "Location:\n",
      "[(0, u'0.040*location + 0.030*hotel + 0.021*great + 0.019*restaurant + 0.011*seattle')]\n",
      "['location', 'traffic', 'minute', 'restaurant', u'hotel', u'great']\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business', 'center', 'computer', 'internet', u'hotel'],\n",
      " 'Check in / front desk': ['stuff', 'check', 'help', 'reservation', u'desk'],\n",
      " 'Cleanliness': ['clean', 'dirty', 'maintain', 'smell', u'room', u'hotel'],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              u'hotel',\n",
      "              u'great'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed', u'hotel'],\n",
      " 'Service': ['service', 'food', 'breakfast', 'buffet', u'hotel', u'room'],\n",
      " 'Value': ['value', 'price', 'quality', 'worth', u'hotel']}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Service:\n",
      "[(0, u'0.047*hotel + 0.032*room + 0.013*service + 0.009*monaco + 0.009*seattle')]\n",
      "['service', 'food', 'breakfast', 'buffet', u'hotel', u'room']\n",
      "Business service:\n",
      "[(0, u'0.077*hotel + 0.015*seattle + 0.010*monaco + 0.009*stay + 0.008*pioneer')]\n",
      "['business', 'center', 'computer', 'internet', u'hotel', u'seattle', u'monaco']\n",
      "Cleanliness:\n",
      "[(0, u'0.051*hotel + 0.036*room + 0.011*seattle + 0.010*clean + 0.008*monaco')]\n",
      "['clean', 'dirty', 'maintain', 'smell', u'room', u'hotel', u'seattle']\n",
      "Check in / front desk:\n",
      "[(0, u'0.036*desk + 0.028*front + 0.013*staff + 0.010*room + 0.009*check')]\n",
      "['stuff', 'check', 'help', 'reservation', u'desk', u'front', u'staff']\n",
      "Value:\n",
      "[(0, u'0.076*hotel + 0.015*seattle + 0.011*monaco + 0.010*stay + 0.009*pioneer')]\n",
      "['value', 'price', 'quality', 'worth', u'hotel', u'seattle', u'monaco']\n",
      "Rooms:\n",
      "[(0, u'0.051*hotel + 0.036*room + 0.009*seattle + 0.009*monaco + 0.007*stay')]\n",
      "['room', 'suite', 'view', 'bed', u'hotel', u'seattle']\n",
      "Location:\n",
      "[(0, u'0.061*hotel + 0.022*great + 0.013*seattle + 0.013*stay + 0.013*pioneer')]\n",
      "['location', 'traffic', 'minute', 'restaurant', u'hotel', u'great', u'seattle']\n",
      "begin bootstrapping iteration, aspect keywords: \n",
      "{'Business service': ['business',\n",
      "                      'center',\n",
      "                      'computer',\n",
      "                      'internet',\n",
      "                      u'hotel',\n",
      "                      u'seattle',\n",
      "                      u'monaco'],\n",
      " 'Check in / front desk': ['stuff',\n",
      "                           'check',\n",
      "                           'help',\n",
      "                           'reservation',\n",
      "                           u'desk',\n",
      "                           u'front',\n",
      "                           u'staff'],\n",
      " 'Cleanliness': ['clean',\n",
      "                 'dirty',\n",
      "                 'maintain',\n",
      "                 'smell',\n",
      "                 u'room',\n",
      "                 u'hotel',\n",
      "                 u'seattle'],\n",
      " 'Location': ['location',\n",
      "              'traffic',\n",
      "              'minute',\n",
      "              'restaurant',\n",
      "              u'hotel',\n",
      "              u'great',\n",
      "              u'seattle'],\n",
      " 'Rooms': ['room', 'suite', 'view', 'bed', u'hotel', u'seattle'],\n",
      " 'Service': ['service', 'food', 'breakfast', 'buffet', u'hotel', u'room'],\n",
      " 'Value': ['value',\n",
      "           'price',\n",
      "           'quality',\n",
      "           'worth',\n",
      "           u'hotel',\n",
      "           u'seattle',\n",
      "           u'monaco']}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initial seeds from LARA paper\n",
    "from gensim import corpora, models\n",
    "seeds = {\"Value\" : [\"value\", \"price\", \"quality\",\"worth\"],\n",
    "         \"Rooms\" : [\"room\", \"suite\", \"view\", \"bed\"],\n",
    "         \"Location\" : [\"location\", \"traffic\", \"minute\", \"restaurant\"],\n",
    "         \"Cleanliness\" : [\"clean\", \"dirty\", \"maintain\", \"smell\"],\n",
    "         \"Check in / front desk\": [\"stuff\", \"check\", \"help\", \"reservation\"],\n",
    "         \"Service\" : [\"service\", \"food\", \"breakfast\", \"buffet\"],\n",
    "         \"Business service\" : [\"business\", \"center\", \"computer\", \"internet\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def aspectSegmentation(reviews, aspects, vocab=[], threshold=0, iterationLimit=3):\n",
    "    #when we have the top chi-squared rated keywords, how many do we take\n",
    "    keywordsToTake = 3\n",
    "    \n",
    "    #bootstrap iterations\n",
    "    for i in range(0, iterationLimit):\n",
    "        \n",
    "        #print our current aspects\n",
    "        print(\"begin bootstrapping iteration, aspect keywords: \")\n",
    "        pp.pprint(aspects)\n",
    "        print(\"\\n\\n\\n\")\n",
    "        labeledSentences = []\n",
    "        for r in reviews:\n",
    "            \n",
    "            #use the pickle tokenizer to split sentences\n",
    "                 \n",
    "            sentences = tokenizer.tokenize(r.decode('utf-8'))\n",
    "\n",
    "                \n",
    "            for s in sentences:\n",
    "                \n",
    "                theseAspects = collections.defaultdict(int)\n",
    "                maxAspect = (0, \"None\")\n",
    "                \n",
    "                #for each aspect count how many times one of those aspect words appears\n",
    "                for a in aspects:\n",
    "                    for word in aspects[a]:\n",
    "                        if \" \"+word+\" \" in s:\n",
    "                            theseAspects[a] += 1\n",
    "                \n",
    "                #find the max occuring aspect for each sentence, take multiple if ties\n",
    "                for a in theseAspects:\n",
    "                    if theseAspects[a] > maxAspect[0]:\n",
    "                        maxAspect = (theseAspects[a], a)\n",
    "                    if theseAspects[a] == maxAspect[0] and a not in maxAspect:\n",
    "                        #label it with multiple aspects\n",
    "                        maxAspect = maxAspect + (a, )\n",
    "                \n",
    "                #add the sentence with labels\n",
    "                labeledSentences.append((s, maxAspect[1:]))\n",
    "            \n",
    "        LDAForAspects = collections.defaultdict(list)\n",
    "        \n",
    "# obtain dictionary of tokenized sentences corresponding to each aspect\n",
    "        for a in aspects:\n",
    "            for s in labeledSentences:\n",
    "                sentenceText=s[0]\n",
    "                sentenceAspects=s[1]\n",
    "                \n",
    "                if a in sentenceAspects:\n",
    "                    sentenceTextTokens=tokenizer2.tokenize(sentenceText)\n",
    "                    sentenceTextTokensNS=[i for i in sentenceTextTokens if not i in stopwords.words(\"english\") and i>2]\n",
    "                    sentenceTextTokensNS_stemmed = [stemmer.stem(i) for i in sentenceTextTokensNS]\n",
    "                    LDAForAspects[a].extend(sentenceTextTokensNS)\n",
    "\n",
    "#Implement LDA to obtain topics\n",
    "        SentenceWords=[]\n",
    "        dictionary={}\n",
    "        corpus={}\n",
    "        for a in aspects:\n",
    "            SentenceWords.append(LDAForAspects[a])\n",
    "            dictionary[a]=corpora.Dictionary([LDAForAspects[a]])\n",
    "            corpus[a] = [dictionary[a].doc2bow([text]) for text in LDAForAspects[a]]\n",
    "            ldamodel = models.ldamodel.LdaModel(corpus[a], num_topics=1, id2word = dictionary[a], passes=20)\n",
    "            print a+\":\"\n",
    "            print(ldamodel.print_topics(num_topics=1, num_words=5))\n",
    "            X=ldamodel.get_topic_terms(0,5)\n",
    "            i=0\n",
    "            while i<len(X):\n",
    "                temp=list(dictionary[a].token2id.keys())[list(dictionary[a].token2id.values()).index(X[i][0])]\n",
    "#     Checking for duplicates\n",
    "                if temp not in aspects[a]:  \n",
    "                    aspects[a].append(temp)\n",
    "                i=i+1\n",
    "            print aspects[a]\n",
    "    return labeledSentences\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "sentencesWLabels = aspectSegmentation(data[\"Content\"], seeds, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"done, time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numToShow = 20\n",
    "count = 0\n",
    "for s in sentencesWLabels:\n",
    "    if 'None' not in s[1]:\n",
    "        print(s)\n",
    "        print(\"\\n\")\n",
    "        count += 1\n",
    "    if count > numToShow:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
