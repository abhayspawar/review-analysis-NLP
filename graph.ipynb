{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import proj_base\n",
    "import scipy.spatial.distance as scpd\n",
    "from numpy.linalg import inv\n",
    "import nltk.sentiment\n",
    "import time\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from textblob import TextBlob\n",
    "import pprint as pp\n",
    "import Sentiment_analysis\n",
    "\n",
    "import sklearn.feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2447, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "data = proj_base.getStandardData(numFiles=25)\n",
    "\n",
    "unchanged = data.copy()\n",
    "aspect = \"Rooms\"\n",
    "proj_base.aspect = aspect\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.apply(Sentiment_analysis.addSentimentScores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 4.291534423828125e-05\n"
     ]
    }
   ],
   "source": [
    "def isFeatureVecNull(fv):\n",
    "    if sum(pd.notnull(fv)) == len(fv):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def getFeatureVec(review, useAspectSentences=False):\n",
    "    if useAspectSentences:\n",
    "        rev2words = sentences2wordlist(review)\n",
    "    else:\n",
    "        rev2words = review2wordlist(review, tokenizer)\n",
    "    return makeFeatureVec(rev2words, model, num_features)\n",
    "\n",
    "\n",
    "def doPSPCosine(r1, r2):\n",
    "    return  1 - scpd.cosine([r1, 1-r1], [r2, 1-r2])\n",
    "    #return scpd.cosine([r1, 1-r1], [r2, 1-r2])\n",
    "\n",
    "def getAllPSP(rev, allRevs):\n",
    "    return allRevs.apply(doPSPCosine, args=(rev,))\n",
    "\n",
    "def getAllSims(rev, allRevs):\n",
    "    return allRevs.apply(cosSim, args=(rev,))\n",
    "\n",
    "def cosSim(r1, r2):\n",
    "    return 1-scpd.cosine(r1, r2)\n",
    "\n",
    "def buildSimilarityMatrix(data):\n",
    "    numNodes = data.shape[0]\n",
    "    sims = data[\"featureVec\"].apply(getAllSims, args=(data[\"featureVec\"],))\n",
    "    \n",
    "                \n",
    "    return sims\n",
    "\n",
    "\n",
    "def getPSP(rev, useAspectSentences=False):\n",
    "    sentences = tokenizer.tokenize(rev.strip())\n",
    "    count = 0\n",
    "    ps = 0\n",
    "    for s in sentences:\n",
    "        count += 1\n",
    "        sentiment = TextBlob(s)\n",
    "        #print(sentiment)\n",
    "        #print(sentiment.polarity)\n",
    "        ps += sentiment.polarity\n",
    "        \n",
    "    return ps\n",
    "\n",
    "\n",
    "def buildPSPSimilarityMatrix(data):\n",
    "    numNodes = data.shape[0]\n",
    "    sims = data[\"psp\"].apply(getAllPSP, args=(data[\"psp\"],))\n",
    "    \n",
    "  \n",
    "                \n",
    "    return sims\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "#similarities = buildSimilarityMatrix(data)\n",
    "#g = buildGraph(data, similarities)\n",
    "time2 = time.time()\n",
    "\n",
    "print(\"time taken\", time2-time1)\n",
    "#similarities\n",
    "\n",
    "def getDataHist(data):\n",
    "    nums = [0]*np.amax(data[aspect])\n",
    "    for i in range(len(data)):\n",
    "        score = data.loc[i][aspect]\n",
    "        if not np.isnan(score):\n",
    "            nums[int(score)-1] += 1\n",
    "    return nums\n",
    "\n",
    "\n",
    "def getBalancedSubsample(data, numUnlabeled=100):\n",
    "    nums = getDataHist(data)\n",
    "    #print(nums)\n",
    "    toGrab = np.amin(nums)\n",
    "    \n",
    "    first = data[data[aspect] == 1.0][0:toGrab]\n",
    "    second = data[data[aspect] == 2.0][0:toGrab]\n",
    "    third = data[data[aspect] == 3.0][0:toGrab]\n",
    "    fourth = data[data[aspect] == 4.0][0:toGrab]\n",
    "    fifth = data[data[aspect] == 5.0][0:toGrab]\n",
    "    unlabeled = data[pd.isnull(data[aspect])][0:numUnlabeled]\n",
    "   \n",
    "    df = pd.concat([first, second, third, fourth, fifth, unlabeled], ignore_index=True)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calcMinLossPredictions(data):\n",
    "    #define constants\n",
    "    #sim = buildSimilarityMatrix(data)\n",
    "    sim = buildPSPSimilarityMatrix(data)\n",
    "    sim = (sim - sim.mean()) / (sim.max() - sim.min())\n",
    "    n = data.shape[0]\n",
    "    print(\"Num data\", n)\n",
    "    a = 5\n",
    "    b = 1\n",
    "    \n",
    "    k = int(n/5)\n",
    "    k_p = 1\n",
    "    M = 300\n",
    "    beta = a*1.0/b\n",
    "    alpha = a*k + b*k_p\n",
    "    isLabeled = np.isnan(data[aspect]) == False \n",
    "    #k = int(.2*sum(isLabeled))\n",
    "    \n",
    "    print(\"num labeled\", sum(isLabeled))\n",
    "    #print(isLabeled)\n",
    "    y = data[\"y\"].values\n",
    "    isLabeled = isLabeled & np.invert(np.isnan(y))\n",
    "    print(\"num labeled\", sum(isLabeled))\n",
    "    y = np.nan_to_num(y)\n",
    "    np.place(y, y==0, 3)\n",
    "    #print(y)\n",
    "    kNN = np.zeros((n, n), float)\n",
    "    k_pNN = np.zeros((n, n), float)\n",
    "    #build kNN matrix\n",
    "    for i in range(n):\n",
    "        if not isLabeled[i]:\n",
    "            #LABELED NEIGHBORS\n",
    "            candidates = np.multiply(isLabeled,sim[i])\n",
    "            kthClosest = sorted(candidates, reverse=True)[k-1]\n",
    "            for j in range(n):\n",
    "                thisSimilar = candidates[j]\n",
    "                if thisSimilar >= kthClosest and i != j:\n",
    "                    #print(\"similar\",i,j, data.loc[i][aspect], data.loc[j][aspect],data.loc[i][\"psp\"], data.loc[j][\"psp\"])\n",
    "                    #print(\"similar\",i,j, data.loc[i][aspect], data.loc[j][aspect])\n",
    "                    kNN[i][j] = 1\n",
    "\n",
    "            candidates = np.multiply(np.invert(isLabeled),sim[i])\n",
    "            kthClosest = sorted(candidates, reverse=True)[k_p]\n",
    "            for j in range(n):\n",
    "                thisSimilar = candidates[j]\n",
    "                if thisSimilar >= kthClosest and i != j:\n",
    "                    #print(\"similar\",i,j, data.loc[i][aspect], data.loc[j][aspect],data.loc[i][\"psp\"], data.loc[j][\"psp\"])\n",
    "                    #print(\"similar, notLabled\",i,j, data.loc[i][aspect], data.loc[j][aspect])\n",
    "                    k_pNN[i][j] = 1\n",
    "    #pp.pprint( kNN)\n",
    "\n",
    "    \n",
    "    c_diag = np.ones(len(data)) + M*isLabeled\n",
    "    C = np.zeros((n, n), int)\n",
    "    \n",
    "    np.fill_diagonal(C, c_diag)\n",
    "    #print(C)\n",
    "    W_p = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if isLabeled[i]:\n",
    "                W_p[i][j] = 0\n",
    "            elif isLabeled[j] and kNN[i][j] == 1:\n",
    "                W_p[i][j] = sim[i][j]\n",
    "            elif not isLabeled[j] and k_pNN[i][j] == 1:\n",
    "                W_p[i][j] = beta*sim[i][j]\n",
    "    #print(\"W_p\",W_p)        \n",
    "    W = np.maximum(W_p, np.transpose(W_p))\n",
    "    #print(\"W \", W)\n",
    "    D = np.zeros((n, n), float)\n",
    "    d_diag = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        d_diag[i] =  sum(W[i])\n",
    "    np.fill_diagonal(D, d_diag)\n",
    "    #pp.pprint(D)\n",
    "    delta = D - W\n",
    "    \n",
    "    constant = alpha*1.0/(k + k_p*beta)\n",
    "    toInv = C + constant*delta\n",
    "    inverse = inv(toInv)\n",
    "    \n",
    "    C_y = C.dot(y)\n",
    "    preds = inverse.dot(C_y)\n",
    "    \n",
    "    #print(preds)\n",
    "    #return np.ceil(preds)\n",
    "    return np.round(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data[\"sentences\"] = data[\"Content\"].apply(tokenizer.tokenize)\n",
    "\n",
    "#sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:68: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[63, 117, 310, 670, 1090]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proj_base.getStandardData(numFiles=50)\n",
    "getDataHist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aspect = \"Location\"\n",
    "#data = unchanged.copy()\n",
    "proj_base.aspect = aspect\n",
    "scoreCols = [col for col in data.columns if  \"score\" in col]\n",
    "X_senti = data[scoreCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900 3900 3900\n"
     ]
    }
   ],
   "source": [
    "trainLoc = pd.notnull(data[aspect])\n",
    "testLoc = np.invert(trainLoc)\n",
    "print(len(trainLoc), len(testLoc), data.shape[0])\n",
    "\n",
    "TfidVect = sklearn.feature_extraction.text.TfidfVectorizer(min_df=10, ngram_range=(1,2),\n",
    "                                                      stop_words = nltk.corpus.stopwords.words('english'))\n",
    "X_tfidf = TfidVect.fit_transform(data['Content'])\n",
    "X_tfidf = X_tfidf.toarray()\n",
    "newX = np.concatenate((X_senti,X_tfidf), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650\n"
     ]
    }
   ],
   "source": [
    "trainTake = [i for i in range(len(trainLoc)) if trainLoc[i]]\n",
    "testTake = [i for i in range(len(trainLoc)) if not trainLoc[i]]\n",
    "\n",
    "lin_clf = sklearn.svm.LinearSVC()\n",
    "X_train = newX[trainTake] \n",
    "X_test = newX[testTake]\n",
    "y_train = data[aspect][trainLoc] \n",
    "y_test = data[aspect][testLoc]\n",
    "lin_clf.fit(X_train,y_train)\n",
    "y_predicted = lin_clf.predict(X_test)\n",
    "print(len(y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = unchanged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(pd.isnull(data[aspect]), sum(pd.notnull(data[aspect]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:68: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[63, 117, 310, 670, 1090]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDataHist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unLabIndex = 0\n",
    "\n",
    "def addY(rev):\n",
    "    global unLabIndex\n",
    "    if np.isnan(rev[aspect]):\n",
    "        rev[\"y\"] = y_predicted[unLabIndex]\n",
    "        unLabIndex += 1\n",
    "    else:\n",
    "        rev[\"y\"] = rev[aspect]\n",
    "    return rev\n",
    "        \n",
    "data = data.apply(addY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:68: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[63, 63, 63, 63, 63]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "proj_base.aspect = aspect\n",
    "data = getBalancedSubsample(data, numUnlabeled=75)\n",
    "\n",
    "getDataHist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business service': ['business',\n",
       "  'center',\n",
       "  'computer',\n",
       "  'internet',\n",
       "  'access',\n",
       "  'wireless',\n",
       "  'convention',\n",
       "  'free',\n",
       "  'fitness',\n",
       "  'computers',\n",
       "  'westlake',\n",
       "  'leisure',\n",
       "  'wired'],\n",
       " 'Check in / front desk': ['stuff',\n",
       "  'check',\n",
       "  'help',\n",
       "  'reservation',\n",
       "  'told',\n",
       "  'early',\n",
       "  'upon',\n",
       "  'arrival',\n",
       "  'desk',\n",
       "  'asked',\n",
       "  'front',\n",
       "  'clerk',\n",
       "  'staff'],\n",
       " 'Cleanliness': ['clean',\n",
       "  'dirty',\n",
       "  'maintain',\n",
       "  'smell',\n",
       "  'comfortable',\n",
       "  'room',\n",
       "  'garbage',\n",
       "  'view',\n",
       "  'bed',\n",
       "  'floor',\n",
       "  'spacious',\n",
       "  'king',\n",
       "  'bathroom'],\n",
       " 'Location': ['location',\n",
       "  'traffic',\n",
       "  'minute',\n",
       "  'restaurant',\n",
       "  'great',\n",
       "  'good',\n",
       "  'pike',\n",
       "  'market',\n",
       "  'place',\n",
       "  'restaurants',\n",
       "  'distance',\n",
       "  'downtown',\n",
       "  'walking'],\n",
       " 'Rooms': ['room',\n",
       "  'suite',\n",
       "  'view',\n",
       "  'bed',\n",
       "  'floor',\n",
       "  'comfortable',\n",
       "  'clean',\n",
       "  'spacious',\n",
       "  'king',\n",
       "  'given',\n",
       "  'beds',\n",
       "  'bathroom',\n",
       "  'space'],\n",
       " 'Service': ['service',\n",
       "  'food',\n",
       "  'breakfast',\n",
       "  'buffet',\n",
       "  'continental',\n",
       "  'customer',\n",
       "  'restaurant',\n",
       "  'good',\n",
       "  'ate',\n",
       "  'excellent',\n",
       "  'location',\n",
       "  'great',\n",
       "  'coffee'],\n",
       " 'Value': ['value',\n",
       "  'price',\n",
       "  'quality',\n",
       "  'worth',\n",
       "  'range',\n",
       "  'location',\n",
       "  'reasonable',\n",
       "  'great',\n",
       "  'good',\n",
       "  'downtown',\n",
       "  'seattle',\n",
       "  'hotel',\n",
       "  'market']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_base.aspectSegmentationChiSquared(data)\n",
    "proj_base.seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Service</th>\n",
       "      <th>Business service</th>\n",
       "      <th>Author</th>\n",
       "      <th>Check in / front desk</th>\n",
       "      <th>No. Helpful</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Content</th>\n",
       "      <th>Value</th>\n",
       "      <th>No. Reader</th>\n",
       "      <th>Overall</th>\n",
       "      <th>y</th>\n",
       "      <th>aspectSentences</th>\n",
       "      <th>psp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Mar 5, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>malisam71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tiny just a warning before you go. the parking...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tiny just a warning before you go. the parking...</td>\n",
       "      <td>0.071042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Aug 31, 2008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Musiclover9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>high quality, low cost at the university inn i...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the rooms are set up with great attention to d...</td>\n",
       "      <td>0.978333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jul 6, 2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>christiem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sadly, all of these bad reviews are correct. w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>our friends also got gift certificates for the...</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nov 5, 2008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7Marini8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great place to stay we stayed two nights at th...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>great place to stay we stayed two nights at th...</td>\n",
       "      <td>1.620833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Oct 11, 2006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jacktraveler</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>excellent choice great experience at this litt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>excellent choice great experience at this litt...</td>\n",
       "      <td>0.934643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms          Date  Location  Service  Business service        Author  \\\n",
       "0    1.0   Mar 5, 2008       3.0      3.0               2.0     malisam71   \n",
       "1    5.0  Aug 31, 2008       5.0      5.0               5.0   Musiclover9   \n",
       "2    1.0   Jul 6, 2008       1.0      1.0               1.0     christiem   \n",
       "3    4.0   Nov 5, 2008       3.0      5.0               NaN      7Marini8   \n",
       "4    5.0  Oct 11, 2006       5.0      5.0               2.0  Jacktraveler   \n",
       "\n",
       "   Check in / front desk  No. Helpful  Cleanliness  \\\n",
       "0                    3.0          NaN          2.0   \n",
       "1                    5.0          1.0          5.0   \n",
       "2                    1.0          0.0          3.0   \n",
       "3                    4.0          NaN          5.0   \n",
       "4                    5.0          5.0          5.0   \n",
       "\n",
       "                                             Content  Value  No. Reader  \\\n",
       "0  tiny just a warning before you go. the parking...    2.0         NaN   \n",
       "1  high quality, low cost at the university inn i...    5.0         1.0   \n",
       "2  sadly, all of these bad reviews are correct. w...    1.0         1.0   \n",
       "3  great place to stay we stayed two nights at th...    4.0         NaN   \n",
       "4  excellent choice great experience at this litt...    4.0         5.0   \n",
       "\n",
       "   Overall    y                                    aspectSentences       psp  \n",
       "0      3.0  3.0  tiny just a warning before you go. the parking...  0.071042  \n",
       "1      5.0  5.0  the rooms are set up with great attention to d...  0.978333  \n",
       "2      1.0  1.0  our friends also got gift certificates for the...  0.550000  \n",
       "3      4.0  3.0  great place to stay we stayed two nights at th...  1.620833  \n",
       "4      5.0  5.0  excellent choice great experience at this litt...  0.934643  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def filterReviewSentencesByWords(rev, words):\n",
    "    #tokenize review into sentences\n",
    "    sentences = tokenizer.tokenize(rev[\"Content\"])\n",
    "    \n",
    "    #print(sentences)\n",
    "    aspSentences = []\n",
    "    for s in sentences:\n",
    "        wordlist = re.sub(\"[^a-zA-Z]\",\" \", s).split()\n",
    "        intersect = set(wordlist).intersection(set(words))\n",
    "        #print(s)\n",
    "        if len(intersect) != 0:\n",
    "            \n",
    "            aspSentences.append(s)\n",
    "\n",
    "    if len(aspSentences) == 0:\n",
    "        rev[\"aspectSentences\"] = rev[\"Content\"]\n",
    "    else:\n",
    "        rev[\"aspectSentences\"] = ' .'.join(aspSentences)\n",
    "\n",
    "    return rev\n",
    "\n",
    "data = data.apply(filterReviewSentencesByWords, axis=1, args=(proj_base.seeds[aspect],))\n",
    "\n",
    "data[\"psp\"] = data[\"aspectSentences\"].apply(getPSP)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doCrossValidation(data, nfolds):\n",
    "    unchanged = data.copy()\n",
    "    total = data.shape[0]\n",
    "    num_test = int(total/nfolds)\n",
    "\n",
    "    rows_list = []\n",
    "    for f in range(nfolds):\n",
    "        #reset data\n",
    "        \n",
    "        data[aspect] = unchanged[aspect]\n",
    "        test_ix = list(range(f*num_test, (f+1)*num_test))\n",
    "        train_ix = [t for t in range(0, total) if t not in test_ix]\n",
    "        \n",
    "        print(\"cross fold nr \", f, \"testSize\", len(test_ix))\n",
    "        #split data into train and test\n",
    "        test = data.loc[test_ix]\n",
    "        train = data.loc[train_ix]\n",
    "        \n",
    "        \n",
    "        truth = unchanged[aspect][test_ix]\n",
    "  \n",
    "        \n",
    "        for t in test_ix:\n",
    "            data.set_value(t, \"y\", np.nan)\n",
    "  \n",
    "\n",
    "        fullpreds = calcMinLossPredictions(data)\n",
    "        predicted = fullpreds[test_ix]\n",
    "        print(\"DONE with fold\", f+1, np.mean(predicted == truth))\n",
    " \n",
    "        \n",
    "        for p in test_ix:\n",
    "            #print(\"pred v truth:\", p,fullpreds[p], data.loc[p][\"y\"], data.loc[p][aspect])\n",
    "            if not np.isnan(data.loc[p][aspect]):\n",
    "                #print(\"huh\")\n",
    "                rows_list.append({\"truth\": data.loc[p][aspect], \"predicted\": fullpreds[p]})\n",
    "            \n",
    "        \n",
    "        for t in test_ix:\n",
    "            data.set_value(t, \"y\", unchanged.loc[t][\"y\"])\n",
    "            #print(\"SET BACK\", data.loc[t][\"y\"], unchanged.loc[t][\"y\"])\n",
    "    return pd.DataFrame(rows_list) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross fold nr  0 testSize 78\n",
      "Num data 390\n",
      "num labeled 315\n",
      "num labeled 252\n",
      "DONE with fold 1 0.230769230769\n",
      "cross fold nr  1 testSize 78\n",
      "Num data 390\n",
      "num labeled 315\n",
      "num labeled 252\n",
      "DONE with fold 2 0.24358974359\n",
      "cross fold nr  2 testSize 78\n",
      "Num data 390\n",
      "num labeled 315\n",
      "num labeled 255\n",
      "DONE with fold 3 0.205128205128\n",
      "cross fold nr  3 testSize 78\n",
      "Num data 390\n",
      "num labeled 315\n",
      "num labeled 249\n",
      "DONE with fold 4 0.205128205128\n",
      "cross fold nr  4 testSize 78\n",
      "Num data 390\n",
      "num labeled 315\n",
      "num labeled 252\n",
      "DONE with fold 5 0.192307692308\n",
      "0.266666666667\n"
     ]
    }
   ],
   "source": [
    "preds = doCrossValidation(data, 5)\n",
    "print(np.mean(preds[\"predicted\"] == preds[\"truth\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266666666667\n",
      "0.333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted  truth\n",
       "0         2.0    3.0\n",
       "1         3.0    5.0\n",
       "2         3.0    1.0\n",
       "3         4.0    3.0\n",
       "4         3.0    5.0\n",
       "5         3.0    1.0\n",
       "6         3.0    4.0\n",
       "7         3.0    1.0\n",
       "8         2.0    1.0\n",
       "9         3.0    3.0\n",
       "10        2.0    3.0\n",
       "11        2.0    2.0\n",
       "12        4.0    3.0\n",
       "13        2.0    2.0\n",
       "14        3.0    2.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "middle = preds[preds[\"truth\"] > 1]\n",
    "middle = preds[preds[\"truth\"] < 5]\n",
    "print(np.mean(preds[\"predicted\"] == preds[\"truth\"]))\n",
    "print(np.mean(middle[\"predicted\"] == middle[\"truth\"]))\n",
    "preds.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(preds[\"predicted\"] == 1), sum(preds[\"predicted\"] == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds.to_csv(aspect+\"Graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\"{0:.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Test confusion matrix function\n",
    "y_test=preds[\"truth\"]\n",
    "y_pred=preds[\"predicted\"]\n",
    "class_names=['1','2','3','4','5']\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
