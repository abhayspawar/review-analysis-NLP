{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternate method to get keywords. LARA method based on Chi-square is basically same, but much better\n",
    "def getKeywords(data = data, freq_threshold = .5, prob_threshold = 0.2, words_per_iter = 4, iters = 3):\n",
    "\n",
    "    #break down reviews into sentences and break down each sentence into words using tokenizer and remove stopwords\n",
    "    # returns list where each item is the list of words in that sentence\n",
    "    sentence_words = []\n",
    "    for review in data['Content']:\n",
    "        review = review.decode('utf-8')\n",
    "        sentences = nltk.tokenize.sent_tokenize(review)\n",
    "        for sentence in sentences:\n",
    "            sentence_words.append([x.lower() for x in nltk.tokenize.word_tokenize(sentence) if x not in stopwords.words('english') and len(x) > 2])    \n",
    "    \n",
    "    seeds =  {\"Value\" : [\"value\", \"price\", \"quality\",\"worth\"],\n",
    "              \"Rooms\" : [\"room\", \"suite\", \"view\", \"bed\"],\n",
    "              \"Location\" : [\"location\", \"traffic\", \"minute\", \"restaurant\"],\n",
    "              \"Cleanliness\" : [\"clean\", \"dirty\", \"maintain\", \"smell\"],\n",
    "              \"Check in / front desk\": [\"stuff\", \"check\", \"help\", \"reservation\"],\n",
    "              \"Service\" : [\"service\", \"food\", \"breakfast\", \"buffet\"],\n",
    "              \"Business service\" : [\"business\", \"center\", \"computer\", \"internet\"]\n",
    "             }\n",
    "\n",
    "    # find Probability(sentence(S) has aspect(A) GIVEN S has word(W)) = count(S that have A and have W) / count(S that have W)\n",
    "\n",
    "    for i in range(iters):\n",
    "        \n",
    "        sents_with_word_asp = {}\n",
    "        sents_with_word = {}\n",
    "        sents_with_aspect = {}\n",
    "        prob_asp_given_word = {}\n",
    "\n",
    "        # calculates counts of (S that have W) and (S that have A and W)\n",
    "        for sentence in sentence_words:\n",
    "            for word in sentence:\n",
    "                sents_with_word[word] = sents_with_word.get(word,0) + 1\n",
    "                for aspect, aspect_words in seeds.items():\n",
    "                    for aspect_word in aspect_words:\n",
    "                        if aspect_word in sentence:\n",
    "                            sents_with_word_asp[(word,aspect)] = sents_with_word_asp.get((word, aspect), 0) + 1\n",
    "                            sents_with_aspect[aspect] = sents_with_aspect.get(aspect,0) + 1\n",
    "                            break\n",
    "\n",
    "        for (word, aspect), count in sents_with_word_asp.items():\n",
    "            #susceptible to low frequencies. hence freq_threshold\n",
    "            #freq_threshold ensures that count(S with  W) is atleast x% of count(S)\n",
    "            if sents_with_word[word] > (freq_threshold/100.0)*len(sentence_words):\n",
    "                prob_asp_given_word[(word,aspect)] = count/float(sents_with_word[word])\n",
    "\n",
    "        prob_asp_given_word_sorted = sorted(prob_asp_given_word.items(), key=itemgetter(1),reverse=True)\n",
    "        \n",
    "        for aspect, word_list in seeds.items():\n",
    "            count = 0\n",
    "            for item in prob_asp_given_word_sorted:\n",
    "                #item is of the form ((word,aspect),probability)\n",
    "                if item[0][1] == aspect:\n",
    "                    if item[0][0] not in word_list:\n",
    "                        if count <= words_per_iter:\n",
    "                            if item[1] >= prob_threshold:\n",
    "                                seeds[aspect].append(item[0][0])\n",
    "                                count += 1\n",
    "                            else:\n",
    "                                #because sorted, the others can't have higher probability\n",
    "                                break\n",
    "                        else:\n",
    "                            # because limiit of words per aspect in this iteration has been reached\n",
    "                            break\n",
    "\n",
    "    return seeds"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
